{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab39fd7a-f81f-42ef-990c-415461e3253b",
   "metadata": {},
   "source": [
    "# **CIK** cleaning tool for `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18718cd3-0425-43af-aa68-491e9587b9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 35)\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "pd.set_option(\"display.max_rows\", 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00034bf-837b-404a-a356-e034037958e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "both = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\")\n",
    "\n",
    "# both_clean = [file for file in both.glob(\"*.csv\")]\n",
    "# len(both_clean)\n",
    "# both_clean[:3]\n",
    "list(both.glob(\"*.csv\"))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa98563-1280-4722-b516-a2f45666188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "both = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\")\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "both_clean = list(both.glob(\"*.csv\"))\n",
    "\n",
    "cik_dfs = []\n",
    "for index, cik in enumerate(selected_cik[:10]):\n",
    "    file_dfs = []\n",
    "    for file in set(both_clean):\n",
    "    # for file in set(cleaned + origin_clean):\n",
    "        if file.name.split(\"-\")[0] == str(cik):\n",
    "            try:\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                if df.empty: continue\n",
    "\n",
    "                df = (df.assign(row_value_zscore = stats.zscore(df.value),\n",
    "                                file_value_sum = df.value.sum(),\n",
    "                                file_value_max = df.value.max(),\n",
    "                                file_value_min = df.value.min(),\n",
    "                                n_holdings = df.shape[0],\n",
    "                                quarter=df.rdate.dt.to_period(freq=\"Q\").astype(str),\n",
    "                                path=file))\n",
    "                df_short = df[['cik', 'cusip9', 'rdate', 'fdate',\n",
    "                               'address', 'file_value_sum', 'file_value_max',\n",
    "                               'file_value_min', 'n_holdings', 'quarter', 'path']].head(1)\n",
    "               \n",
    "\n",
    "                file_dfs.append(df_short)\n",
    "                df = None\n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "      \n",
    "    cik_df = pd.concat(file_dfs)\n",
    "    file_dfs = None\n",
    "\n",
    "    cik_dfs.append(cik_df)\n",
    "big_df = pd.concat(cik_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c62d76-f87a-4527-b896-f89fe56f953a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -V\n",
    "# big_df.head(2)\n",
    "# df.head()\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "sorted(selected_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8273b7-1060-43d3-9416-ba6f6015773c",
   "metadata": {},
   "source": [
    "### Non-working altair only version - no way to select or copy/paste the addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89d82c-acfa-4368-ad4a-f638d333ddb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair import datum\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "input_dropdown = alt.binding_select(options=selected_cik, name='cik ')\n",
    "cik_selection = alt.selection_single(fields=['cik'], bind=input_dropdown)\n",
    "brush = alt.selection(type='multi')\n",
    "\n",
    "scatter = alt.Chart(big_df).mark_point().transform_calculate(value_billion=\"datum.value / 1000000000\")\\\n",
    "    .encode(\n",
    "    alt.X('quarter:O'),\n",
    "    alt.Y('file_value_sum:Q'),\n",
    "    \n",
    "    # alt.Row('cik'),\n",
    "    tooltip=['quarter:O','address:N', \n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$.3s\") ,\n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$~s\"),\n",
    "             alt.Tooltip('fdate:T')\n",
    "            ]\n",
    "    # alt.Tooltip(['quarter:O','accession_number:N', 'value:O']),\n",
    "    \n",
    ").add_selection(cik_selection\n",
    ").transform_filter(cik_selection\n",
    ").add_selection(brush\n",
    ").properties(width=800, height=200)\n",
    "\n",
    "ranked_text = alt.Chart(big_df).mark_text().encode(\n",
    "    y=alt.Y('row_number:O',axis=None)\n",
    ").transform_window(\n",
    "    row_number='row_number()'\n",
    ").transform_filter(\n",
    "    brush\n",
    ").transform_window(\n",
    "    rank='rank(row_number)'\n",
    ").transform_filter(\n",
    "    alt.datum.rank<5\n",
    ")\n",
    "\n",
    "# Data Tables\n",
    "address = ranked_text.encode(text='address:N').properties(title='address')\n",
    "quarter = ranked_text.encode(text='quarter:O').properties(title='quarter')\n",
    "value = ranked_text.encode(text='file_value_sum:Q').properties(title='value')\n",
    "text = alt.hconcat(address, quarter, value) # Combine data tables\n",
    "\n",
    "alt.vconcat(\n",
    "    scatter,\n",
    "    text\n",
    ").resolve_legend(\n",
    "    color=\"independent\"\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c55f6e-83d1-495c-a1c3-3af84f9ec1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_text.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe2c22-2612-4d51-8e20-e84b400a010c",
   "metadata": {},
   "source": [
    "#### panel + altair - doesn't work yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44895e7-577d-4434-8523-b7c6aee5cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.cik.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71bfbb-1cbd-4622-9724-a1f4319b8db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import altair as alt\n",
    "# import pandas as pd\n",
    "# import panel as pn\n",
    "# from altair import datum\n",
    "# pn.extension(\"vega\", sizing_mode=\"stretch_width\")\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# cik_input_pn = pn.widgets.Select(name='Select CIK', options = big_df.cik.unique().tolist(), placeholder = 'ex: 2230', value = 2230)\n",
    "# ###\n",
    "# input_dropdown = alt.binding_select(options=selected_cik, name='cik ')\n",
    "# cik_selection = alt.selection_single(fields=['cik'], bind=input_dropdown, init={'cik': 5272}, name='cik_select')\n",
    "# brush = alt.selection(type='multi')\n",
    "\n",
    "# scatter = alt.Chart(big_df).mark_point()\\\n",
    "#     .encode(\n",
    "#     alt.X('quarter:O'),\n",
    "#     alt.Y('file_value_sum:Q'),\n",
    "    \n",
    "#     # alt.Row('cik'),\n",
    "#     tooltip=['quarter:O','address:N', \n",
    "#              alt.Tooltip('file_value_sum:Q', format=\"$.3s\") ,\n",
    "#              alt.Tooltip('file_value_sum:Q', format=\"$~s\"),\n",
    "#              alt.Tooltip('fdate:T')\n",
    "#             ]\n",
    "#     # alt.Tooltip(['quarter:O','accession_number:N', 'value:O']),\n",
    "    \n",
    "# # ).add_selection(cik_selection\n",
    "# # ).transform_filter(cik_selection\n",
    "# # ).add_selection(brush\n",
    "# # ).properties(width=800, height=200)\n",
    "    \n",
    "# ).add_selection(cik_selection\n",
    "# ).transform_filter(cik_selection\n",
    "# ).properties(width=800, height=200)\n",
    "\n",
    "# scatter\n",
    "\n",
    "# vega_pane = pn.pane.Vega(scatter, debounce=10, height=600)\n",
    "# vega_pane\n",
    "# # @pn.depends(vega_pane.selection.param.brush)\n",
    "# # def filtered_table(selection):\n",
    "# #     # return selection.value\n",
    "# #     if not selection:\n",
    "# #         return \"## No selection\"\n",
    "# #     query = \" & \".join(\n",
    "# #         f'{crange[0]:.3f} <= {col} <= {crange[1]:.3f}'\n",
    "# #         for col, crange in selection.items()\n",
    "# #     )\n",
    "# #     return pn.pane.DataFrame(big_df.query(query))\n",
    "\n",
    "\n",
    "# # Data Tables\n",
    "\n",
    "\n",
    "# # table = pn.Row(filtered_table, height=300, scroll=True)\n",
    "# # component = pn.Column(vega_pane, table).servable()\n",
    "# # component\n",
    "\n",
    "# # template = pn.template.FastListTemplate(\n",
    "# #     site=\"Awesome Panel\",\n",
    "# #     title=\"Panel supports Vega and Altair Selections\",\n",
    "# #     accent=\"#F08080\",\n",
    "# #     main=[component],\n",
    "# # ).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251697a-3809-4211-8fee-4d535b43b61e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Working altair example with different data, but with a caveat.\n",
    "1. It uses the `tabulator` parameter selector and not the table display option. It still can work fine, but I can't programatically extract the seleced data and use it as a variable. (or at least I think so). It also makes it so when I manually select the line in that tabulator, it can by deleted if I hit `del` or `backspace`\n",
    "2. It feels too complicated and now it only works with `x` and `y` being both numerical \n",
    "3. It has to be launched as a separte panel dashboard (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baaf3c-d05a-46f3-b107-f9ab080956ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import altair as alt\n",
    "# import panel as pn\n",
    "# import pandas as pd\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "# # from pyodide.http import open_url\n",
    "\n",
    "# pn.config.sizing_mode = 'stretch_width'\n",
    "\n",
    "# url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv'\n",
    "# penguins = pd.read_csv(url).dropna()\n",
    "# cols = list(penguins.columns)[2:6]\n",
    "\n",
    "\n",
    "# filter_dropdown = pn.widgets.Select(name='Island',\n",
    "#                              options=penguins.island.unique().tolist(),\n",
    "#                              value='Torgersen').servable(target='filter-dropdown-widget')\n",
    "# x = pn.widgets.Select(name='x', options=cols, value='bill_depth_mm').servable(target='x-widget')\n",
    "# y = pn.widgets.Select(name='y', options=cols, value='bill_length_mm').servable(target='y-widget')\n",
    "# n_clusters = pn.widgets.IntSlider(name='n_clusters', start=1, end=5, value=3).servable(target='n-widget')\n",
    "\n",
    "# brush = alt.selection_interval(name='brush')  # selection of type \"interval\"\n",
    "\n",
    "# def get_clusters(n_clusters, filter_dropdown):\n",
    "#     kmeans = KMeans(n_clusters=n_clusters)\n",
    "#     est = kmeans.fit(penguins[cols].values)\n",
    "#     df = penguins.copy()\n",
    "#     df['labels'] = est.labels_.astype('str')\n",
    "#     df = df.query(f'island == \"{filter_dropdown}\"')\n",
    "#     return df\n",
    "\n",
    "# def get_chart(x, y, df, filter_dropdown):\n",
    "#     centers = df.groupby('labels').mean()\n",
    "#     return (\n",
    "#       alt.Chart(df)\n",
    "#           .mark_point(size=100)\n",
    "#           .encode(\n",
    "#               x=alt.X(x, scale=alt.Scale(zero=False)),\n",
    "#               y=alt.Y(y, scale=alt.Scale(zero=False)),\n",
    "#               shape='labels',\n",
    "#               color='species'\n",
    "#           ).add_selection(brush).properties(width=800) +\n",
    "#       alt.Chart(centers)\n",
    "#           .mark_point(size=250, shape='cross', color='black')\n",
    "#           .encode(x=x+':Q', y=y+':Q')\n",
    "#     )\n",
    "\n",
    "# intro = pn.pane.Markdown(\"\"\"\n",
    "# This app provides an example of **building a simple dashboard using\n",
    "# Panel**.\\n\\nIt demonstrates how to take the output of **k-means\n",
    "# clustering on the Penguins dataset** using scikit-learn,\n",
    "# parameterizing the number of clusters and the variables to\n",
    "# plot.\\n\\nThe plot and the table are linked, i.e. selecting on the plot\n",
    "# will filter the data in the table.\\n\\n The **`x` marks the center** of\n",
    "# the cluster.\n",
    "# \"\"\").servable(target='intro')\n",
    "\n",
    "# chart = pn.pane.Vega(debounce=5).servable(target='cluster-plot')\n",
    "# table = pn.widgets.Tabulator(pagination='remote', page_size=10).servable(target='table')\n",
    "\n",
    "# def update_table(event=None):\n",
    "#     table.value = get_clusters(n_clusters.value, filter_dropdown.value)\n",
    "\n",
    "# n_clusters.param.watch(update_table, 'value')\n",
    "# filter_dropdown.param.watch(update_table, 'value')\n",
    "\n",
    "# @pn.depends(x, y, n_clusters, filter_dropdown, watch=True)\n",
    "# def update_chart(*events):\n",
    "#     chart.object = get_chart(x.value, y.value, table.value, filter_dropdown.value)\n",
    "#     chart.selection.param.watch(update_filters, 'brush')\n",
    "\n",
    "# def update_filters(event=None):\n",
    "#     filters = []\n",
    "#     for k, v in (getattr(event, 'new') or {}).items():\n",
    "#         filters.append(dict(field=k, type='>=', value=v[0]))\n",
    "#         filters.append(dict(field=k, type='<=', value=v[1]))\n",
    "#         table.filters = filters\n",
    "\n",
    "# update_table()\n",
    "# update_chart()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffc1dc-041c-4ba6-858b-7d20d0e7d68a",
   "metadata": {},
   "source": [
    "### **Fully working** code with hvplot. It's got the plot, dropdown, table and the selection captured as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b991b4-a42b-4a49-80ad-74adeea1b29b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "both = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\")\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "\n",
    "# cleaned = [file for file in TR_01_TEST_676_CIK_CSV_CLEANED.glob(\"*.csv\")]\n",
    "# origin_clean = [file for file in TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN.glob(\"*.csv\")]\n",
    "both_clean = [file for file in both.glob(\"*.csv\")]\n",
    "\n",
    "cik_dfs = []\n",
    "for index, cik in enumerate(selected_cik[:10]):\n",
    "    file_dfs = []\n",
    "    for file in set(both_clean):\n",
    "    # for file in set(cleaned + origin_clean):\n",
    "        if file.name.split(\"-\")[0] == str(cik):\n",
    "            try:\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                if df.empty: continue\n",
    "\n",
    "                df = (df.assign(row_value_zscore = stats.zscore(df.value),\n",
    "                                file_value_sum = df.value.sum().round(0),\n",
    "                                file_value_max = df.value.max(),\n",
    "                                file_value_min = df.value.min(),\n",
    "                                n_holdings = df.shape[0],\n",
    "                                quarter=df.rdate.dt.to_period(freq=\"Q\").astype(str),\n",
    "                                quarter_period=df.rdate.dt.to_period(freq='Q'),\n",
    "                                path=file))\n",
    "                df_short = df[['cik', 'cusip9', 'rdate', 'fdate',\n",
    "                               'address', 'file_value_sum', 'file_value_max',\n",
    "                               'file_value_min', 'n_holdings', 'quarter', 'path']].head(1)\n",
    "               \n",
    "\n",
    "                file_dfs.append(df_short)\n",
    "                df = None\n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "      \n",
    "    cik_df = pd.concat(file_dfs)\n",
    "    file_dfs = None\n",
    "\n",
    "    cik_dfs.append(cik_df)\n",
    "big_df = pd.concat(cik_dfs)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8632f6-307c-4cbb-9a3b-5b92803f3cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format/formatting of amounts to million or billion\n",
    "big_df['value_format'] = big_df['file_value_sum'] / 1_000_000\n",
    "big_df['value_format'] = big_df['value_format'].apply(lambda x: f'{x:.2f}M' if x < 1000 else f'{x/1000:.2f}B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da26c1-ad26-4eb5-9846-a9ed6317aa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fully working hvplot data cleaning tool\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "pn.extension('tabulator', template='material', sizing_mode='stretch_width')\n",
    "import hvplot.pandas # noqa\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "cik_dropdown = pn.widgets.Select(name='cik',\n",
    "                                     options=big_df.cik.unique().tolist(),\n",
    "                                     value=big_df.cik.unique().tolist()[0])\n",
    "\n",
    "big_dfi =  big_df.interactive(sizing_mode='stretch_width')\n",
    "filtered_big_dfi = big_dfi[(big_dfi['cik'] == cik_dropdown)]\n",
    "# points plot\n",
    "points_plot = filtered_big_dfi.hvplot(x='rdate',\n",
    "                                      y='file_value_sum',\n",
    "                                      kind='points',\n",
    "                                      height=350, \n",
    "                                      width=900,\n",
    "                                      persist=True,\n",
    "                                      hover_cols=['address', 'fdate','quarter', 'value_format', 'n_holdings'],\n",
    "                                      formatters={'value_format': '%s', 'file_value_sum': 'int'},\n",
    "                                      yformatter='%d')\n",
    "ls = hv.link_selections.instance(unselected_alpha=0.08)\n",
    "\n",
    "# Table is not yet dynamically linked to the linked selection\n",
    "table = filtered_big_dfi[['cik', 'rdate', 'fdate', 'address', 'file_value_sum', 'n_holdings', 'quarter']].pipe(ls.filter, selection_expr=ls.param.selection_expr).pipe(\n",
    "    pn.widgets.Tabulator, pagination='remote', page_size=10)\n",
    "\n",
    "column = pn.Column(filtered_big_dfi.widgets(),ls(points_plot.holoviews()), ls(table.panel()))\n",
    "\n",
    "column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445790fe-39cc-4269-af7c-42646e6fda08",
   "metadata": {},
   "source": [
    "### **Captures the selection** into a list of file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f47f0-8f80-4b42-bbe2-70d1c58e568e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# captures the selection into a list of file paths\n",
    "records_to_edit = ls.filter(big_df).query(f'cik == {cik_dropdown.value}')\n",
    "l = records_to_edit.path.to_list()\n",
    "l\n",
    "# l[0]\n",
    "# [print(i) for i in records_to_edit.path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3555bb-e5b3-49cc-85d6-e01d8323b99b",
   "metadata": {},
   "source": [
    "### **Opens file** in LibreOffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b936703-af90-422c-ac93-a9e73b433ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "file_to_open = l[1]\n",
    "os.system(f\"open {file_to_open} -a LibreOffice\")\n",
    "i = input(\"did you correct the file?\")\n",
    "if i == \"yes\":\n",
    "    print(f\"file: {file_to_open} is finished\")\n",
    "    # continue\n",
    "else: \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e4629-7bd7-4f99-beb7-b8b16b31f295",
   "metadata": {},
   "source": [
    "###  **Divides** the `df` by 1_000 and writes it to the original file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0226c8-4993-4b34-a007-f873f2fdb87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# devide by 1_000\n",
    "from pathlib import Path\n",
    "for file in l:\n",
    "    file = Path(file)\n",
    "    try:\n",
    "        # print(file)\n",
    "        df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "        df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "        df = (df.assign(value=df.value/1000))\n",
    "        # df = (df.assign(value=df.value * 1000))\n",
    "        df.to_csv(file, index=False)\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d865835-e5a0-45de-94ae-c3596c32c339",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **DELETES** files - CAREFUL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47f09e-32bd-4d8e-81ba-3c592b57f49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete files\n",
    "import os\n",
    "\n",
    "for file in l:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "        print(f\"{file} deleted successfully\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72f628-433b-41c1-bc43-0eff12b49f49",
   "metadata": {},
   "source": [
    "### **DELETES** records  !!! that  contain certain string - CAREFUL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af78eb3-dcfd-48e8-8408-9a61bfe2a152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete individual records, data frame\n",
    "from pathlib import Path\n",
    "for file in l[:]:\n",
    "    file = Path(file)\n",
    "\n",
    "    try:\n",
    "        # print(file)\n",
    "        df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "        df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "        mask_delete_if_contains =  (df['cusip9'].str.contains('COM'))  | (df['cusip9'].str.contains('54928210C')) | \\\n",
    "                                   (df['cusip9'].str.contains('832696306')) | (df['cusip9'].str.contains('6986571CO'))\n",
    "        \n",
    "        display(df[mask_delete_if_contains])\n",
    "        df = df.drop(df[mask_delete_if_contains].index)\n",
    "\n",
    "        # print('#' * 40)\n",
    "        \n",
    "\n",
    "        df.to_csv(file, index=False)\n",
    "    except:\n",
    "        print(\"error\")    \n",
    "# TEGIESLTD         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab1125-6f06-4a66-bb36-7aaf32cefb98",
   "metadata": {},
   "source": [
    "### **COPIES** `cusip, value, shares` from  `csv` **A** to **B** while keeping the dates and metadata of **B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9f1ce-2dc9-40aa-911f-d0a07d6aea03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_from = '/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH/313028-0000313028-07-000001.csv'\n",
    "file_to = '/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH/313028-0000313028-07-000002.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef97bdb-0673-4efa-9a28-5124f328dd42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_from = l[0]\n",
    "file_to = l[1]\n",
    "file_from, file_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af4c8c-a992-4af3-97cc-093a562720c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the contents of one CSV, another well changing dates and quarter\n",
    "file_from = Path(file_from)\n",
    "file_to = Path(file_to)\n",
    "\n",
    "try:\n",
    "    # print(file)\n",
    "    df_from = pl.read_csv(file_from, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "    df_from = df_from.to_pandas().astype(pd_dtypes_validation)\n",
    "\n",
    "    df_to = pl.read_csv(file_to, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "    df_to = df_to.to_pandas().astype(pd_dtypes_validation)\n",
    "    display('before transform')\n",
    "    display('from', df_from.head(3))\n",
    "    display('from value', df_from.value.sum())\n",
    "    display('to value', df_to.value.sum())\n",
    "\n",
    "    df_from.rdate, df_from.fdate, df_from.address, df_from.form = \\\n",
    "    df_to.rdate.head(1).values[0], df_to.fdate.head(1).values[0], df_to.address.head(1).values[0], df_to.form.head(1).values[0]\n",
    "    # print(file)\n",
    "    # print(f'value before: {df.value.sum()/1_000_000}M')\n",
    "\n",
    "\n",
    "    display('after transform')\n",
    "    display(df_from.head(3))\n",
    "    display(df_from.value.sum())\n",
    "\n",
    "    # print(file, f'value after: {df.value.sum()/1_000_000}M')\n",
    "    # print('#' * 40)\n",
    "\n",
    "\n",
    "    # df_from.to_csv(file_to, index=False)\n",
    "except:\n",
    "    print(\"error\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786174a-aa63-4897-a612-7e833e5b3748",
   "metadata": {},
   "source": [
    "### **Delete** records that contains some substring from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba0368-7268-4f06-9327-130396ee829d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete individual records with some substring form files\n",
    "from pathlib import Path\n",
    "for file in big_df.path.values[:]:\n",
    "    file = Path(file)\n",
    "    # print(file)\n",
    "    if file.exists():\n",
    "        df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True)\n",
    "    else: continue\n",
    "    df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "    # df = df.query('cusip9.str.contains(\"[a-zA-Z]{4,}\", regex=True)')\n",
    "    # df = df.query('cusip9.str.contains(\"TEGIES\")')\n",
    "    # if not df.empty: display(df)\n",
    "    df = df.drop(df.query('cusip9.str.contains(\"TEGIES\")').index)\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "    # df = df.query('cusip9.str.contains(\"TEGIES\")')\n",
    "    # if not df.empty: display(df)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2439ee5-dd7b-43ed-b7a2-4118e70e9943",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "sorted(selected_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8655a55c-a91b-4e6f-8333-cb5f4ab00b22",
   "metadata": {},
   "source": [
    "## Merges together **my/sec_app** and **dropbox**  filings for the selected CIKs\n",
    "* The merge is `fdate` based. Every filing before `2014` comes from cleaned `dropbox` folder\n",
    "* From 2014 and onwards is from `sec_app` parquet based filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94705cf1-4e64-4093-a29e-8af74c25dacb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# reads the combined tr_04 to extract all ciks\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['cik', 'rdate']\n",
    "my_file = Path(r\"/Users/yo_macbook/Documents/app_data/sec_apps_data/tr_04_filings_parquet_cik\")\n",
    "df = pd.concat(pd.read_parquet(f, columns=columns).drop_duplicates(subset=['cik', 'rdate']) for f in my_file.glob(\"*.parquet\"))\n",
    "all_cik = df.cik.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b1217-0fec-4217-bb6e-3a24fa0b9fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "non676_cik = sorted(list(set(all_cik).difference(set(selected_cik))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95faa2-09c8-4eca-911c-67ef2905d634",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Code that brings together ALL csv (from before 2014-01-01) and parquet (from after 2014-01-01)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "dropbox_csv = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED\")\n",
    "sec_app_parq = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_ALL_PARQ_SEC_APP')\n",
    "# temp\n",
    "non676_cik = sorted(list(set(all_cik).difference(set(selected_cik))))\n",
    "# non676_cik = [4977]\n",
    "# selected_cik = [3133, 3521, 4962]\n",
    "\n",
    "## dropbox csv\n",
    "columns_dropbox = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'type', 'dsource']\n",
    "\n",
    "pd_dtypes_validation_dropbox = {'cusip9': str, 'form': 'category',\n",
    "            'value': 'float64', 'shares': 'float64', 'type': 'category',\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "pl_dtypes_dropbox = {'cusip9': str ,'form': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "## sec_app parquet\n",
    "columns_sec_app = ['cik', 'cusip','value', 'shares','rdate', 'fdate',\\\n",
    "            'accession_number', 'submission_type', 'type', 'dsource', 'file']\n",
    "\n",
    "pd_dtypes_validation_sec_app = {'cusip': str, 'submission_type': 'category', 'value': 'float64', \n",
    "            'shares': 'float64', 'type': 'category', 'cik' : 'int64',\n",
    "            'accession_number': 'category',  'dsource': 'category', 'file':'category'}\n",
    "\n",
    "pl_dtypes_sec_app = {'cusip': str ,'submission_type': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str,\n",
    "            'cik' : pl.Int64, 'accession_number': str,  'dsource': str, 'file': str}\n",
    "\n",
    "\n",
    "list_cik_in_dir = lambda dir_: sorted(set([int(file.stem.split('-')[0]) for file in Path(dir_).glob('*')]))\n",
    "list_cik_after = lambda dir_, cik_after: [cik for cik in list_cik_in_dir(dir_) if cik > cik_after ]\n",
    "list_cik_after(sec_app_parq, 1958491)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_from = 1\n",
    "l_to = 20\n",
    "cutoff_date = '2014-01-01'\n",
    "cik_dfs = []\n",
    "zscore_dfs = []\n",
    "# for index, cik in enumerate(non676_cik[l_from:l_to]):\n",
    "for index, cik in enumerate(list_cik_after(sec_app_parq, 1958491)):\n",
    "    if any(dropbox_csv.glob(f\"{cik}-*.csv\")): \n",
    "        file_dfs = []\n",
    "        for file in dropbox_csv.glob(f\"{cik}-*.csv\"):\n",
    "            if file.name.split(\"-\")[0] == str(cik):\n",
    "                try:               \n",
    "                    df_dropbox = pl.read_csv(file, columns=columns_dropbox, dtypes=pl_dtypes_dropbox, parse_dates=True)                \n",
    "                    df_dropbox = df_dropbox.to_pandas().astype(pd_dtypes_validation_dropbox)\n",
    "                    if df_dropbox.empty or df_dropbox.fdate.max() >= pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue\n",
    "                    df_dropbox = (df_dropbox.assign(file_value_sum = df_dropbox.value.sum(),\n",
    "                                                    n_holdings = df_dropbox.cusip9.nunique(),\n",
    "                                                    quarter=df_dropbox.rdate.dt.to_period(freq=\"Q\").astype(str),\n",
    "                                                    file=file)\n",
    "                                 )\n",
    "                    df_dropbox_short = df_dropbox[['cik', 'cusip9', 'rdate', 'fdate', 'address', \n",
    "                                   'file_value_sum', 'n_holdings', 'quarter', 'file']].head(1)\n",
    "\n",
    "                    df_dropbox_short = df_dropbox_short.rename(columns={'cusip9': 'cusip', 'address': 'accession_number'}) \n",
    "                    cik_dfs.append(df_dropbox_short)                \n",
    "                    df_dropbox = None\n",
    "                except Exception as e:\n",
    "                    print(f\"Problem reading file... {file.name}\")\n",
    "                    print(e)\n",
    "\n",
    "    # else: print(f'for cik: {cik} no     csv files before {cutoff_date}')\n",
    "\n",
    "# ######\n",
    "    # print('marching on to parquet')\n",
    "    # print('#' * 40)\n",
    "    if any(sec_app_parq.glob(f\"{cik}-*.parquet\")):      \n",
    "        for file in sec_app_parq.glob(f\"{cik}-*.parquet\"):\n",
    "            try:\n",
    "                df_sec_app = pl.read_parquet(file, columns=columns_sec_app) \n",
    "                df_sec_app = df_sec_app.to_pandas().astype(pd_dtypes_validation_sec_app)\n",
    "                if df_sec_app.empty or df_sec_app.fdate.max() < pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue               \n",
    "                df_sec_app = (df_sec_app.assign(file_value_sum = df_sec_app.value.sum().round(),\n",
    "                                n_holdings = df_sec_app.cusip.nunique(),\n",
    "                                quarter=df_sec_app.rdate.dt.to_period(freq=\"Q\").astype(str),\n",
    "                                file=file)\n",
    "                             )\n",
    "                df_sec_app_short = df_sec_app[['cik', 'cusip', 'rdate', 'fdate', 'accession_number',\n",
    "                                'file_value_sum', 'n_holdings', 'quarter', 'file']].head(1)\n",
    "\n",
    "                cik_dfs.append(df_sec_app_short)\n",
    "                df_sec_app = None\n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "    # else: print(f'for cik: {cik} no parquet files from {cutoff_date} on')\n",
    "\n",
    "if cik_dfs: \n",
    "    common_df = pd.concat(cik_dfs)\n",
    "    common_df['zscore'] = common_df.groupby(['cik']).file_value_sum.transform(lambda x: stats.zscore(x))\n",
    "    common_df['cik_mean_sum'] = common_df.groupby(['cik']).file_value_sum.mean()\n",
    "    common_df['value_sum_shift'] = common_df.groupby(['cik', 'quarter']).file_value_sum.pct_change()\n",
    "\n",
    "    # format/formatting of amounts to million or billion for the chart\n",
    "    common_df['value_format'] = common_df['file_value_sum'] / 1_000_000\n",
    "    common_df['value_format'] = common_df['value_format'].apply(lambda x: f'{x:.2f}M' if x < 1000 else f'{x/1000:.2f}B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cda037-625f-42b8-a9d4-1b8f2a15dbb4",
   "metadata": {},
   "source": [
    "## Fully working, hvplot based data cleaning tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fb009-4cd4-4b3b-ab59-85422e0d9336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fully working hvplot data cleaning tool\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "pn.extension('tabulator', template='material', sizing_mode='stretch_width')\n",
    "import hvplot.pandas # noqa\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "cik_dropdown = pn.widgets.Select(name='CIK',\n",
    "                                     options=common_df.cik.unique().tolist(),\n",
    "                                     value=common_df.cik.unique().tolist()[0])\n",
    "\n",
    "common_dfi =  common_df.round().interactive(sizing_mode='stretch_width')\n",
    "filtered_common_dfi = common_dfi[(common_dfi['cik'] == cik_dropdown)]\n",
    "# # points plot\n",
    "points_plot = filtered_common_dfi.hvplot(x='rdate',\n",
    "                                      y='file_value_sum',\n",
    "                                      kind='points',\n",
    "                                      height=350, \n",
    "                                      width=900,\n",
    "                                      persist=True,\n",
    "                                      hover_cols=['fdate','quarter', 'value_format', 'n_holdings', 'accession_number', 'zscore'],\n",
    "                                      yformatter='%d')\n",
    "ls_common = hv.link_selections.instance(unselected_alpha=0.08)\n",
    "ls_common.show_regions=True\n",
    "\n",
    "\n",
    "@pn.depends(cik_dropdown.param.value,watch=True)\n",
    "def clear_selection_on_drop_down_change(self):\n",
    "    ls_common.selection_expr = None\n",
    "\n",
    "\n",
    "# # Table is not yet dynamically linked to the linked selection\n",
    "table = (filtered_common_dfi[['cik', 'rdate', 'fdate', 'accession_number','file_value_sum', 'n_holdings', 'quarter', 'zscore', 'value_sum_shift']]\n",
    "        .sort_values(by='quarter')\n",
    "        .pipe(ls_common.filter, selection_expr=ls_common.param.selection_expr)\n",
    "        .pipe(pn.widgets.Tabulator, pagination='remote', page_size=10))\n",
    "\n",
    "column = pn.Column(filtered_common_dfi.widgets(),ls_common(points_plot.holoviews()).opts(hv.opts.Points(active_tools=['box_select'])),\n",
    "                   ls_common(table.panel()))\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abf9ac-65d8-4710-84e6-6ed784f086b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# captures the selection into a list of file paths\n",
    "records_to_edit = ls_common.filter(common_df).query(f'cik == {cik_dropdown.value}').sort_values(by='quarter')\n",
    "l = records_to_edit.file.to_list()\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e754616-1047-4d1e-8d0d-892d9a82436b",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  **Divides** the `df` by 1_000 and writes it to the original file. `txt` or `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e16a3d-47c3-4e8e-9039-4d19590768fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# func: divide value by 1000\n",
    "# divide_by_1000(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f74db-e050-4483-8173-369264e29551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# devide by 1_000\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def divide_by_1000(path_list):\n",
    "    \"\"\"\n",
    "    input: list of file paths to deal with\n",
    "    returns: divides `value` by 1000 and \n",
    "    saves it back to the original file\n",
    "    csv or parquet\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in path_list:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            if file.suffix == '.parquet':\n",
    "                df = pd.read_parquet(file)\n",
    "                df = (df.assign(value=df.value/1000))\n",
    "                # df = (df.assign(value=df.value * 1000))\n",
    "                df.to_parquet(file, index=False)\n",
    "                print('parquet', file)\n",
    "                \n",
    "            elif file.suffix == '.csv':\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                df = (df.assign(value=df.value/1000))\n",
    "                # df = (df.assign(value=df.value * 1000))\n",
    "                df.to_csv(file, index=False)\n",
    "                print('csv', file)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a5332-bd54-4c0e-be8f-575bfa513e4e",
   "metadata": {},
   "source": [
    "### Open `csv` in Libreoffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54890a1e-c0ef-4b00-ba6a-15e54d62216f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "file_to_open = l[1]\n",
    "os.system(f\"open {file_to_open} -a LibreOffice\")\n",
    "i = input(\"did you correct the file?\")\n",
    "if i == \"yes\":\n",
    "    print(f\"file: {file_to_open} is finished\")\n",
    "    # continue\n",
    "else: \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99381960-f0e6-4b07-8fb1-b587ffd70add",
   "metadata": {},
   "source": [
    "### Open parquet file in Tad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834414a-6585-4463-972d-b62c9f054af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "file_to_open = l[0]\n",
    "os.system(f\"open {file_to_open} -a Tad\")\n",
    "i = input(\"did you correct the file?\")\n",
    "if i == \"yes\":\n",
    "    print(f\"file: {file_to_open} is finished\")\n",
    "    # continue\n",
    "else: \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852ca34-629c-438c-aa14-628ece8d8a6e",
   "metadata": {},
   "source": [
    "### **DELETE** records with **TEGIES** substring in `cusip` from a dataframe with file paths column and write back to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180292ea-e090-45bf-92e5-c0e2a46a0f41",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove_cusip_w_substring(common_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f0cf7-6964-4a38-8f78-47dcc0fef7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def remove_cusip_w_substring(common_df):\n",
    "    \"\"\"\n",
    "    input: dataframe\n",
    "    returns: removes cusip containing certain substring and \n",
    "    saves it back to the original files\n",
    "    csv or parquet\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in common_df.file.values[:]:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            if file.suffix == '.parquet' and file.exists():\n",
    "                df = pd.read_parquet(file)\n",
    "                if not df.query('cusip.str.contains(\"TEGIES\")').empty: \n",
    "                    print(f'found TEGIES in {file} ')\n",
    "                    df = df.drop(df.query('cusip.str.contains(\"TEGIES\")').index)\n",
    "                    df.to_parquet(file, index=False)\n",
    "                    print('saved new df to parquet', file)\n",
    "            elif file.suffix == '.csv' and file.exists():\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                if not df.query('cusip9.str.contains(\"TEGIES\")').empty: \n",
    "                    print(f'found TEGIES in {file} ')\n",
    "                    df = df.drop(df.query('cusip9.str.contains(\"TEGIES\")').index)\n",
    "                    df.to_csv(file, index=False)\n",
    "                    print('saved new df to csv', file)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a7850-842b-47f4-950c-f71afdf67218",
   "metadata": {},
   "source": [
    "### **DELETES** entire files. CAREFULL !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687303c4-f330-40e0-ba9f-4bbcfef3e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # delete files\n",
    "# import os\n",
    "\n",
    "# for file in l:\n",
    "#     try:\n",
    "#         os.remove(file)\n",
    "#         print(f\"{file} deleted successfully\")\n",
    "#     except OSError as e:\n",
    "#         print(f\"Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363bcda-f72c-4c91-b589-1b677eceecfa",
   "metadata": {},
   "source": [
    "### **SWAP** columns `value` and `shares`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86d11d-5087-459b-bc99-815a9d5cd053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# swaps columns `value` and `shares`\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def swap_value_shares(path_list, save_flag = False):\n",
    "    \"\"\"\n",
    "    input: list of file paths to deal with\n",
    "    returns: # swaps columns `value` and `shares` in a file\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in path_list:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            if file.suffix == '.parquet':\n",
    "                \n",
    "                df = pd.read_parquet(file)\n",
    "                df = (df.assign(value=df.shares,\n",
    "                                shares=df.value))\n",
    "                if save_flag: df.to_parquet(file, index=False)\n",
    "                print('parquet')\n",
    "            elif file.suffix == '.csv':\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                df = (df.assign(value=df.shares,\n",
    "                                shares=df.value))\n",
    "                print(df.rdate.dt.to_period(freq='Q').squeeze()[0],  df.value.sum()/1_000_000, df.cik)\n",
    "                if save_flag: df.to_csv(file, index=False)\n",
    "                print('csv')\n",
    "        except:\n",
    "            print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c48bad-1ca7-4940-b618-d089fec494e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# swap_value_shares(l, save_flag = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de826f-16c5-49b0-a312-e38189059c66",
   "metadata": {},
   "source": [
    "### In some cases, `value` has to be divided by 10 or 100 and not 1000 because of bad raw data. Whoever submitted it made a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb837d-9bbb-4095-b2fd-6d8fe4c5fef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7d9a0c-4fa9-45e4-8e33-52c9258c43f0",
   "metadata": {},
   "source": [
    "### Change the value in a cell in a filing given a specific condition in `cusip` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793d657-d9d5-4237-acf2-800a14cdce70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# \"92206C706\"\n",
    "# \"808524805\"\n",
    "# \"88160R101\"\n",
    "# \"46434V266\"\n",
    "# \"78468R887\"\n",
    "# \"922908744\"\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def change_cusip_record(path_list, cusip, save_flag = False):\n",
    "    \"\"\"\n",
    "    input: list of file paths to deal with\n",
    "    returns: # changed file with certain cusip values/shares changed\n",
    "    and written to the same file\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in path_list:\n",
    "        try:\n",
    "            if file.suffix == '.parquet':\n",
    "              \n",
    "                df = pd.read_parquet(file)\n",
    "\n",
    "                record_to_edit = df.query(f'cusip.str.contains(\"{cusip}\")')[['cusip', 'value', 'shares']]\n",
    "                # print(record_to_edit)\n",
    "                \n",
    "                if not record_to_edit.empty: \n",
    "                    \n",
    "                    print(f\"found CUSIP TO CHANGE in {record_to_edit}\")\n",
    "                    df.loc[record_to_edit.index, 'value'] = df.loc[record_to_edit.index, 'value'].values/1000\n",
    "                    # print(record_to_edit['value']=record_to_edit['value']/1000)\n",
    "                    print(f\"CHANGED record {df.query(f'cusip==@cusip')}\")\n",
    "                    # print(f\"found CUSIP TO CHANGE in {r}\")\n",
    "                    \n",
    "                    if save_flag: df.to_parquet(file, index=False)\n",
    "                    print('saved new df to parquet', file)\n",
    "\n",
    "        except:\n",
    "            print(\"error\")\n",
    "    # return df.value.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d0024-1b1c-417b-b3a1-480d23972a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change_cusip_record(l, \"922908744\", save_flag = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d68e53-e0a1-4f77-b9ce-f382f8da2b69",
   "metadata": {},
   "source": [
    "# Combining together **final** manually cleaned versions of both datasets, `dropbox` and `sec_app` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63737f10-6623-4ad6-9b43-213346ac88e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f\"{parq}/{cik}-*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3a040-cb70-4a11-8a1b-3b9ced25c381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sec_app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564abab5-9052-46fd-acd2-f4e0ef4b10e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "# Code that brings together ALL csv (from before 2014-01-01) and parquet (from after 2014-01-01)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "# from scipy import stats\n",
    "\n",
    "\n",
    "parq = Path(r\"/Users/yo_macbook/Documents/app_data/TR_02_1_FILINGS_PARQ\")\n",
    "data_load_logs = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_3_DATA_LOAD_LOGS')\n",
    "## sec_app parquet\n",
    "columns_sec_app = ['cik', 'cusip','value', 'shares','rdate', 'fdate',\\\n",
    "            'accession_number','file', 'data_load_run']\n",
    "\n",
    "pd_dtypes_validation_sec_app = {'cusip': str, 'value': 'float64', 'shares': 'float64', 'cik' : 'int64',\n",
    "            'accession_number': 'category', 'file':'category'}\n",
    "\n",
    "pl_dtypes_sec_app = {'cusip': str , 'value': pl.Float64, 'shares': pl.Float64,\n",
    "            'cik' : pl.Int64, 'accession_number': str, 'file': str}\n",
    "\n",
    "# cik_list = sorted(set([file.stem.split('-')[0] for file in parq.iterdir() if file.suffix == '.parquet']))\n",
    "cik_list = pl.read_parquet(f'{data_load_logs}/*.parquet').filter(pl.col(\"qa\") == 'no').get_column('cik').unique().to_list()\n",
    "# cik_list = [40545]\n",
    "\n",
    "cik_dfs = []\n",
    "zscore_dfs = []\n",
    "for index, cik in enumerate(cik_list):\n",
    "\n",
    "    if any(parq.glob(f\"{cik}-*.parquet\")):      \n",
    "        for file in parq.glob(f\"{cik}-*.parquet\"):\n",
    "            try:\n",
    "                df_sec_app = pl.read_parquet(file, columns=columns_sec_app) \n",
    "                df_sec_app = df_sec_app.to_pandas().astype(pd_dtypes_validation_sec_app)\n",
    "                df_sec_app = (df_sec_app.assign(file_value_sum = df_sec_app.value.sum().round(),\n",
    "                                n_holdings = df_sec_app.cusip.nunique(),\n",
    "                                quarter=df_sec_app.rdate.dt.to_period(freq=\"Q\").astype(str),\n",
    "                                avg_value=df_sec_app.value.sum().round()/df_sec_app.cusip.nunique(),\n",
    "                                file=file))\n",
    "                                \n",
    "                df_sec_app_short = df_sec_app[['cik', 'cusip', 'rdate', 'fdate', 'accession_number',\n",
    "                                'file_value_sum', 'n_holdings', 'avg_value','quarter', 'file', 'data_load_run']].head(1)\n",
    "\n",
    "                cik_dfs.append(df_sec_app_short)\n",
    "                df_sec_app = None\n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "\n",
    "if cik_dfs: \n",
    "    common_df = pd.concat(cik_dfs).sort_values(by=['cik', 'quarter'])\n",
    "    # common_df['zscore'] = common_df.groupby(['cik']).file_value_sum.transform(lambda x: stats.zscore(x))\n",
    "    # common_df['cik_mean_sum'] = common_df.groupby(['cik']).file_value_sum.mean()\n",
    "    common_df['avg_value_pct'] = common_df.groupby(['cik', 'quarter']).file_value_sum.transform('pct_change').round(4)\n",
    "    # common_df['avg_value_pct'] = common_df.groupby(['cik', 'quarter'])['file_value_sum'].transform(lambda x: x.pct_change().round(4))\n",
    "    # common_df['avg_value_pct'] = common_df['file_value_sum'].transform(lambda x: x.pct_change().round(4))\n",
    "\n",
    "\n",
    "    # format/formatting of amounts to million or billion for the chart\n",
    "    common_df['value_format'] = common_df['file_value_sum'] / 1_000_000\n",
    "    common_df['value_format'] = common_df['value_format'].apply(lambda x: f'{x:.2f}M' if x < 1000 else f'{x/1000:.2f}B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0a330-32c5-45ba-b688-8ec24e3d23a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b80d6-ecf0-42b3-9f74-ee9a723faad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fully working hvplot data cleaning tool\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "pn.extension('tabulator', template='material', sizing_mode='stretch_width')\n",
    "import hvplot.pandas # noqa\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "cik_dropdown = pn.widgets.Select(name='CIK',\n",
    "                                    options=common_df.cik.unique().tolist(),\n",
    "                                    value=common_df.cik.unique().tolist()[0])\n",
    "\n",
    "common_dfi =  common_df.round().interactive(sizing_mode='stretch_width')\n",
    "filtered_common_dfi = common_dfi[(common_dfi['cik'] == cik_dropdown)]\n",
    "# # points plot\n",
    "points_plot = filtered_common_dfi.hvplot(x='rdate',\n",
    "                                    y='file_value_sum',\n",
    "                                    kind='points',\n",
    "                                    height=350, \n",
    "                                    width=900,\n",
    "                                    persist=True,\n",
    "                                    hover_cols=['fdate','quarter', 'value_format', 'n_holdings', 'accession_number', 'avg_value_pct'],\n",
    "                                    yformatter='%d')\n",
    "ls_common = hv.link_selections.instance(unselected_alpha=0.08)\n",
    "ls_common.show_regions=True\n",
    "\n",
    "\n",
    "@pn.depends(cik_dropdown.param.value,watch=True)\n",
    "def clear_selection_on_drop_down_change(self):\n",
    "    ls_common.selection_expr = None\n",
    "\n",
    "\n",
    "# # Table is not yet dynamically linked to the linked selection\n",
    "table = (filtered_common_dfi[['cik', 'rdate', 'fdate', 'accession_number','file_value_sum', 'value_format','n_holdings', 'quarter', 'avg_value_pct', 'data_load_run']]\n",
    "        .sort_values(by='quarter')\n",
    "        .pipe(ls_common.filter, selection_expr=ls_common.param.selection_expr)\n",
    "        .pipe(pn.widgets.Tabulator, pagination='remote', page_size=10))\n",
    "\n",
    "column = pn.Column(filtered_common_dfi.widgets(),ls_common(points_plot.holoviews()).opts(hv.opts.Points(active_tools=['box_select'])),\n",
    "                ls_common(table.panel()))\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23de205-a568-48db-8db9-7ee323e629bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# captures the selection into a list of file paths\n",
    "records_to_edit = ls_common.filter(common_df).query(f'cik == {cik_dropdown.value}').sort_values(by='quarter')\n",
    "l = records_to_edit.file.to_list()\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42451726-ddc4-4ecf-ab46-e538f8b26edc",
   "metadata": {},
   "source": [
    "##  **Multiply** the `value` by 1_000 and writes it to the original `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499553e-e400-414a-9ddc-6af6db19e6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### func: MULTIPLY value by 1000\n",
    "data_load_logs = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_3_DATA_LOAD_LOGS')\n",
    "mult_by_1000(l, data_load_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c1821-e905-486f-ad80-8543dbdf6ea4",
   "metadata": {},
   "source": [
    "##  **Divide** the `value` by 1_000 and writes it to the original `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3c8a7-da0e-41ee-a6b0-8af7834f309a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### func: DIVIDE value by 1_000\n",
    "data_load_logs = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_3_DATA_LOAD_LOGS')\n",
    "divide_by_1000(l, data_load_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3a942-1225-4a74-b0c0-c6194a4d97ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# two func, divide by 1_000 and multiply by 1_000\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def divide_by_1000(path_list, log_dir):\n",
    "    for file in path_list:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            df = pl.read_parquet(file)\n",
    "            df = df.with_columns([(pl.col(\"value\") / 1000).alias(\"value\")])\n",
    "            df.write_parquet(file)\n",
    "            df_log = pl.read_parquet(f'{data_load_logs}/{df[0, \"data_load_run\"]}*.parquet')\n",
    "            df_log = df_log.with_columns([\n",
    "                    pl.when(pl.col(\"cik\") == df[0, 'cik']).then(\"yes\").otherwise(pl.col(\"qa\")).alias(\"qa\")\n",
    "                                    ])\n",
    "            df_log.write_parquet(f'{data_load_logs}/{df[0, \"data_load_run\"]}.parquet')\n",
    "\n",
    "            print(f'original file {file.name} changed \"value divide by 1_000\" and the log file {df[0, \"data_load_run\"]} updated')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "def mult_by_1000(path_list, log_dir):\n",
    "    for file in path_list:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            df = pl.read_parquet(file)\n",
    "            df = df.with_columns([(pl.col(\"value\") * 1000).alias(\"value\")])\n",
    "            df.write_parquet(file)\n",
    "            df_log = pl.read_parquet(f'{data_load_logs}/{df[0, \"data_load_run\"]}*.parquet')\n",
    "            df_log = df_log.with_columns([\n",
    "                    pl.when(pl.col(\"cik\") == df[0, 'cik']).then(\"yes\").otherwise(pl.col(\"qa\")).alias(\"qa\")\n",
    "                                    ])\n",
    "            df_log.write_parquet(f'{data_load_logs}/{df[0, \"data_load_run\"]}.parquet')\n",
    "\n",
    "            print(f'original file {file.name} changed \"value * 1_000\" and the log file {df[0, \"data_load_run\"]} updated')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c182b-76bd-4ac6-a018-a7e4a55a3036",
   "metadata": {},
   "source": [
    "## **Open** in Tad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e6b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "file_to_open = l[0]\n",
    "os.system(f\"open {file_to_open} -a Tad\")\n",
    "i = input(\"did you correct the file?\")\n",
    "if i == \"yes\":\n",
    "    print(f\"file: {file_to_open} is finished\")\n",
    "    # continue\n",
    "else: \n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e91073-94be-485a-ac10-b178e5936418",
   "metadata": {},
   "source": [
    "## **Compare** Total `value` and `shares` from filings in the list to see if the might need to be swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54bd78-55df-4f22-a968-530a3f94e72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "            \n",
    "comp_value_shares = lambda l: [print(f'filing {index+1}: Total value - {pd.read_parquet(file).value.sum()} filing {index+1}: Total shares - {pd.read_parquet(file).shares.sum()}') for index, file in enumerate(l)]\n",
    "comp_value_shares(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696d47e-ca36-40c1-a293-5c21548f3c5f",
   "metadata": {},
   "source": [
    "## **SWAP** columns `value` and `shares`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7d7f9-1796-4165-bcec-dfe7184a584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap_value_shares(l, save_flag = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4978c-d868-4163-a6ae-5dc613f2b2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# swaps columns `value` and `shares`\n",
    "from pathlib import Path\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def swap_value_shares(path_list, save_flag = False):\n",
    "    \"\"\"\n",
    "    input: list of file paths to deal with\n",
    "    returns: # swaps columns `value` and `shares` in a file\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in path_list:\n",
    "        file = Path(file)\n",
    "        try:\n",
    "            if file.suffix == '.parquet':\n",
    "                \n",
    "                df = pd.read_parquet(file)\n",
    "                df = (df.assign(value=df.shares,\n",
    "                                shares=df.value))\n",
    "                if save_flag: df.to_parquet(file, index=False)\n",
    "                print('parquet')\n",
    "            elif file.suffix == '.csv':\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                df = (df.assign(value=df.shares,\n",
    "                                shares=df.value))\n",
    "                print(df.rdate.dt.to_period(freq='Q').squeeze()[0],  df.value.sum()/1_000_000, df.cik)\n",
    "                if save_flag: df.to_csv(file, index=False)\n",
    "                print('csv')\n",
    "        except:\n",
    "            print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043f3d2-2383-4a06-95dd-4306ae85d946",
   "metadata": {},
   "source": [
    "## !!! In **data_load_logs** change all `qa` to `yes`. This is **ONLY** done after all manual data quality test is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904a168-8716-4e8a-92a0-d1d04c6cfc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_load_logs = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_3_DATA_LOAD_LOGS')\n",
    "log_file_list = data_load_logs.glob('*.parquet')\n",
    "\n",
    "for file in log_file_list:\n",
    "    df = pl.read_parquet(file)\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"qa\") == 'no').then(\"yes\").otherwise(\"yes\").alias(\"qa\")\n",
    "                  ])\n",
    "    df.write_parquet(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c53c0-8047-4f28-a098-125ffd16ed45",
   "metadata": {},
   "source": [
    "### **DELETE** entire files. CAREFULL !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35678ccf-2186-4fff-ba7d-144272741776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9e46c-a045-493e-94c4-a8361ed0750b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # delete files\n",
    "# import os\n",
    "\n",
    "# for file in l:\n",
    "#     try:\n",
    "#         os.remove(file)\n",
    "#         print(f\"{file} deleted successfully\")\n",
    "#     except OSError as e:\n",
    "#         print(f\"Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57321d29-45a7-4100-9ebd-be2a71db205b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9b279-5256-434a-b1d0-04dd3dd4d1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcf2a8-8c5f-45dd-88a3-779107bc6700",
   "metadata": {},
   "source": [
    "### pandas with clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad122ba-58df-446e-aec5-47a18f2bddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clip = pd.read_clipboard()\n",
    "\n",
    "# widths = [33, 17, 9, 9, 9, 10]\n",
    "# widths = [28, 7, 9, 16, 12, 4]\n",
    "# widths = [33, 17, 9, 9, 9, 3]\n",
    "# widths = [33, 6, 11, 14, 14, 3]\n",
    "# widths = [32, 10, 16, 9, 9, 4]\n",
    "widths = [32, 17, 10, 10, 9, 3]\n",
    "\n",
    "columns = ['issuer', 'title', 'cusip', 'value', 'shares', 'shrsprn']\n",
    "# df = pd.read_fwf(file, widths=widths, names=columns,engine='python', header=None,  index_col=False, dtype=({'cusip':str})).ffill()\n",
    "\n",
    "# df.to_csv(Path.joinpath(file.parent, 'filing_copy.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f2c51-34f6-4af7-89ae-f578d16b8c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_clip.ffill().to_clipboard(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d73054-4b27-4a50-80a4-9bd4fb9600cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example demonstrating how to put together a cross-selector app based\n",
    "on the Auto MPG dataset.\n",
    "\"\"\"\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "\n",
    "from bokeh.sampledata.autompg import autompg\n",
    "\n",
    "df = autompg.copy()\n",
    "\n",
    "ORIGINS = ['North America', 'Europe', 'Asia']\n",
    "\n",
    "# data cleanup\n",
    "df.origin = [ORIGINS[x-1] for x in df.origin]\n",
    "\n",
    "df['mfr'] = [x.split()[0] for x in df.name]\n",
    "df.loc[df.mfr=='chevy', 'mfr'] = 'chevrolet'\n",
    "df.loc[df.mfr=='chevroelt', 'mfr'] = 'chevrolet'\n",
    "df.loc[df.mfr=='maxda', 'mfr'] = 'mazda'\n",
    "df.loc[df.mfr=='mercedes-benz', 'mfr'] = 'mercedes'\n",
    "df.loc[df.mfr=='toyouta', 'mfr'] = 'toyota'\n",
    "df.loc[df.mfr=='vokswagen', 'mfr'] = 'volkswagen'\n",
    "df.loc[df.mfr=='vw', 'mfr'] = 'volkswagen'\n",
    "del df['name']\n",
    "\n",
    "columns = sorted(df.columns)\n",
    "discrete = [x for x in columns if df[x].dtype == object]\n",
    "continuous = [x for x in columns if x not in discrete]\n",
    "quantileable = [x for x in continuous if len(df[x].unique()) > 20]\n",
    "\n",
    "x = pnw.Select(name='X-Axis', value='mpg', options=quantileable)\n",
    "y = pnw.Select(name='Y-Axis', value='hp', options=quantileable)\n",
    "size = pnw.Select(name='Size', value='None', options=['None'] + quantileable)\n",
    "color = pnw.Select(name='Color', value='None', options=['None'] + quantileable)\n",
    "\n",
    "@pn.depends(x.param.value, y.param.value, color.param.value, size.param.value)\n",
    "def create_figure(x, y, color, size):\n",
    "    opts = dict(cmap='rainbow', width=800, height=600, line_color='black')\n",
    "    if color != 'None':\n",
    "        opts['color'] = color\n",
    "    if size != 'None':\n",
    "        opts['size'] = hv.dim(size).norm()*20\n",
    "    return hv.Points(df, [x, y], label=\"%s vs %s\" % (x.title(), y.title())).opts(**opts)\n",
    "\n",
    "widgets = pn.WidgetBox(x, y, color, size, width=200)\n",
    "\n",
    "pn.Row(widgets, create_figure).servable('Cross-selector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf6741-b17d-4c5a-b599-fb3c6c30d3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "pn.extension('tabulator', template='material', sizing_mode='stretch_width')\n",
    "import hvplot.pandas # noqa\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "penguins_url = \"https://raw.githubusercontent.com/vega/vega/master/docs/data/penguins.json\"\n",
    "penguins_df = pd.read_json(penguins_url)\n",
    "penguins_df.head()\n",
    "\n",
    "island_dropdown = pn.widgets.Select(name='Island',\n",
    "                                     options=penguins_df.Island.unique().tolist(),\n",
    "                                     value=penguins_df.Island.unique().tolist()[0])\n",
    "\n",
    "\n",
    "penguins_dfi =  penguins_df.interactive(sizing_mode='stretch_width')\n",
    "penguins_dfi = penguins_dfi[(penguins_dfi['Island'] == island_dropdown)]\n",
    "# # points plot\n",
    "points_plot = penguins_dfi.hvplot(x='Species',\n",
    "                                      y='Body Mass (g)',\n",
    "                                      kind='points',\n",
    "                                      height=350, \n",
    "                                      width=900,\n",
    "                                      persist=True,\n",
    "                                      hover_cols=['Body Mass (g)','Beak Length (mm)', 'Flipper Length (mm)'],\n",
    "                                      yformatter='%d')\n",
    "\n",
    "ls_common = hv.link_selections.instance(unselected_alpha=0.08)\n",
    "\n",
    "# # Table is not yet dynamically linked to the linked selection\n",
    "table = penguins_dfi[['Island', 'Species', 'Sex', 'Body Mass (g)','Beak Length (mm)', 'Flipper Length (mm)']].pipe(ls_common.filter, selection_expr=ls_common.param.selection_expr).pipe(\n",
    "    pn.widgets.Tabulator, pagination='remote', page_size=10)\n",
    "\n",
    "column = pn.Column(penguins_dfi.widgets(),\n",
    "                   ls_common(points_plot.holoviews()).opts(hv.opts.Points(active_tools=['box_select'])),\n",
    "                   ls_common(table.panel()))\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2efd8-53b9-4569-88da-e61f69e534c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import hvplot.pandas # noqa\n",
    "\n",
    "from bokeh.sampledata.penguins import data as penguins_df\n",
    "\n",
    "pn.extension('tabulator', template='material', sizing_mode='stretch_width')\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "island_dropdown = pn.widgets.Select(name='island',\n",
    "                                     options=penguins_df.island.unique().tolist(),\n",
    "                                     value=penguins_df.island.unique().tolist()[0])\n",
    "\n",
    "penguins_dfi =  penguins_df.interactive(sizing_mode='stretch_width')\n",
    "penguins_dfi = penguins_dfi[(penguins_dfi['island'] == island_dropdown)]\n",
    "# # points plot\n",
    "points_plot = penguins_dfi.hvplot(x='species',\n",
    "                                      y='body_mass_g',\n",
    "                                      kind='points',\n",
    "                                      height=350, \n",
    "                                      width=900,\n",
    "                                      persist=True,\n",
    "                                      hover_cols=['body_mass_g','bill_length_mm', 'flipper_length_mm'],\n",
    "                                      yformatter='%d')\n",
    "\n",
    "\n",
    "ls_common = hv.link_selections.instance()\n",
    "ls_common.show_regions=True\n",
    "\n",
    "\n",
    "@pn.depends(island_dropdown.param.value,watch=True)\n",
    "def clear_selection_on_drop_down_change(self):\n",
    "    ls_common.selection_expr = None\n",
    "\n",
    "\n",
    "# # Table is not yet dynamically linked to the linked selection\n",
    "table = penguins_dfi[['island', 'species', 'sex', 'body_mass_g','bill_length_mm', 'flipper_length_mm']].pipe(ls_common.filter, selection_expr=ls_common.param.selection_expr).pipe(\n",
    "    pn.widgets.Tabulator, pagination='remote', page_size=10)\n",
    "\n",
    "column = pn.Column(penguins_dfi.widgets(),ls_common(points_plot.holoviews()), ls_common(table.panel()))\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af1900-74e8-4641-ae05-3ddb98114484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca1ecc-9479-48fe-b217-1acc9e647514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f93a5-febe-4095-be3f-99adbe7c27e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_packages(file_path):\n",
    "    with open(file_path) as file:\n",
    "        packages = {line.split(\"==\")[0]: line.split(\"==\")[1].strip() for line in file}\n",
    "    return packages\n",
    "\n",
    "\n",
    "def compare_package_files(file1, file2):\n",
    "    packages1 = read_packages(file1)\n",
    "    packages2 = read_packages(file2)\n",
    "\n",
    "    common_packages = set(packages1.keys()) & set(packages2.keys())\n",
    "    only_in_file1 = set(packages1.keys()) - set(packages2.keys())\n",
    "    only_in_file2 = set(packages2.keys()) - set(packages1.keys())\n",
    "\n",
    "    different_versions = {\n",
    "        package: (packages1[package], packages2[package])\n",
    "        for package in common_packages\n",
    "        if packages1[package] != packages2[package]\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"common_packages\": common_packages,\n",
    "        \"different_versions\": different_versions,\n",
    "        \"only_in_file1\": only_in_file1,\n",
    "        \"only_in_file2\": only_in_file2,\n",
    "    }\n",
    "\n",
    "\n",
    "comparison_result = compare_package_files(\"not_working_env_packages.txt\", \"working_env_packages.txt\")\n",
    "\n",
    "print(\"Common packages:\")\n",
    "print(comparison_result[\"common_packages\"])\n",
    "\n",
    "print(\"\\nPackages with different versions:\")\n",
    "for package, versions in comparison_result[\"different_versions\"].items():\n",
    "    print(f\"{package}: {versions[0]} (file1) vs {versions[1]} (file2)\")\n",
    "\n",
    "print(\"\\nPackages only in file1:\")\n",
    "print(comparison_result[\"only_in_file1\"])\n",
    "\n",
    "print(\"\\nPackages only in file2:\")\n",
    "print(comparison_result[\"only_in_file2\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
