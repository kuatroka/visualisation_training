{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762cd43-a2cb-4073-8bbb-2b472b93ce0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import polars as pl\n",
    "# import duckdb\n",
    "import os\n",
    "import pandera as pa\n",
    "# import io\n",
    "\n",
    "pd.set_option('display.max_columns', 35)\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "\n",
    "FROM_EXPERIMENT_CSV_IN = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_02_EXP_SELECT_CIK_CSV\")\n",
    "TO_EXPERIMENT_PARQUET = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_03_EXP_SELECT_CIK_PARQUET\")\n",
    "\n",
    "REDUCED_SELECT_CSV =Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_02_EXP_SELECT_CIK_CSV_REDUCED\")\n",
    "\n",
    "#----\n",
    "processed_tables_copy = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\processed_tables_copy\")\n",
    "TR_00_ALL_CSV_REDUCED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_ALL_CSV_REDUCED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466597c7-1706-4cec-b325-063f477cbb56",
   "metadata": {},
   "source": [
    "### Transforming original `csv` files into new `csv` with reduced number of columns\n",
    "* new folder with reduced `csv`: \n",
    "  1. From `processed_tables_copy =Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\processed_tables_copy\")`\n",
    "  2. To ```TR_00_ALL_CSV_REDUCED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_ALL_CSV_REDUCED\")```\n",
    "  \n",
    "* It's a one-off code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321300de-052b-4b2f-a962-de7d123b1be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "columns = ['cik', 'cusip8', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "           'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str,\n",
    "          'putCall': str, 'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, \n",
    "          'nameOfIssuer': str, 'cik' : pl.Int64, 'address': str, 'type': str,'num5': str,\n",
    "          'deviation':str, 'shrout':str,'num3': str,'num2': str, 'num6':str,'num7': str,'num4': str,\n",
    "           'votingAuthority': str, 'in_universe': str,'prc': str, 'split': str,\n",
    "           'investmentDiscretion': str, 'rdate': str, 'fdate': str, 'dsource': str}\n",
    "\n",
    "pd_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': 'category', 'putCall': 'category',\n",
    "           'shrsOrPrnAmt': 'category', 'value': 'float64', 'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "           'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "# pd_dtypes_validation = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': 'category', 'putCall': 'category',\n",
    "#            'shrsOrPrnAmt': 'category', 'value': 'Int64', 'shares': 'Int64', 'type': 'category', 'nameOfIssuer': str,\n",
    "#            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "\n",
    "# for file in processed_tables_copy.rglob(\"*.csv\"):\n",
    "#     new_file_name = file.parts[-2]+\"-\"+file.name\n",
    "#     new_file_path = Path(os.path.join(TR_00_ALL_CSV_REDUCED, new_file_name))\n",
    "#     if new_file_path.exists():  continue\n",
    "\n",
    "    \n",
    "#     schema = pl.scan_csv(file).schema\n",
    "#     read_cols = list(set(schema.keys()).intersection(columns))\n",
    "#     df = pl.read_csv(file, columns=read_cols, dtypes=dtypes)\n",
    "\n",
    "#     for col in columns:\n",
    "#         if col not in df.columns:\n",
    "#             df = df.with_column(pl.lit(None, dtype=dtypes[col]).alias(col))\n",
    "\n",
    "#     df = df.with_columns([pl.col(\"rdate\").str.strptime(pl.Date, fmt=\"%Y%m%d\"),\n",
    "#                         pl.col(\"fdate\").str.strptime(pl.Date, fmt=\"%Y%m%d\"),\n",
    "#                         pl.col(\"cusip8\").str.to_uppercase(),\n",
    "#                         pl.col(\"cusip9\").str.to_uppercase(),\n",
    "#                         pl.lit('dropbox').alias('dsource')]).select(columns)  \n",
    "\n",
    "#     df.write_csv(new_file_path, sep=\",\")\n",
    "#     df = df.to_pandas().astype(pd_dtypes_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd4be3-1f12-4639-a554-1f21bf2d3e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(list(processed_tables_copy.rglob(\"*.csv\"))), len(list(TR_00_ALL_CSV_REDUCED.glob(\"*.csv\")))\n",
    "# (308585, 308585)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f14d4b-a45a-482c-bf2a-cb2ee9b1b7fd",
   "metadata": {},
   "source": [
    "### Working on selected **reduced csv** and **txt** files to manually improve the data quality with `pandera`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b81d8-2b8b-48f9-9aeb-721eee47134d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "len(selected_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b70c53-1b0b-4157-9146-5dd967d16e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy raw `TXT` filings for the selected 676 ciks (active in 1999 and 2000) to a separate folder `TR_00_TEST_676_CIK_TXT`\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "# main_directory = Path('E:\\\\app_data\\\\sec_apps_data\\\\speed_test\\\\filings_13f_full')\n",
    "# filings_directory = main_directory / 'filings'\n",
    "# selected_filings_directory = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_TEST_676_CIK_TXT\")\n",
    "\n",
    "# # Create the selected_filings_directory if it doesn't exist\n",
    "# selected_filings_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Iterate through the subdirectories in the filings directory\n",
    "# for subdir in filings_directory.iterdir():\n",
    "#     if int(subdir.name) in selected_cik:\n",
    "#         # Copy the subdirectory to the selected_filings_directory\n",
    "#         shutil.copytree(subdir, selected_filings_directory / subdir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ace740-b66a-4d8c-a4d6-c63f6bd50da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy reduced `CSV` filings for the selected 676 ciks (active in 1999 and 2000) to a separate folder `TR_01_TEST_676_CIK_CSV_REDUCED`\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "TR_00_ALL_CSV_REDUCED = Path(r'E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_ALL_CSV_REDUCED')\n",
    "TR_01_TEST_676_CIK_CSV_REDUCED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_REDUCED\")\n",
    "\n",
    "# Create the selected_filings_directory if it doesn't exist\n",
    "TR_01_TEST_676_CIK_CSV_REDUCED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterate through the subdirectories in the filings directory\n",
    "# for file in TR_00_ALL_CSV_REDUCED.glob(\"*.csv\"):\n",
    "#     # file.name\n",
    "#     # if subdir.name.isdigit() and int(subdir.name) in selected_cik:\n",
    "#     if int(subdir.name) in selected_cik:\n",
    "#         # Copy the subdirectory to the selected_filings_directory\n",
    "#         shutil.copytree(subdir, selected_filings_directory / subdir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100456f7-5c3f-400a-8778-fc39afad0bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(clean_processed_files) # 1st round 8204"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd0290-f5e0-4427-9972-0609be369c80",
   "metadata": {},
   "source": [
    "### Running `pandera` validation through the **selected** cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dedbc-bbbf-4e96-9c6f-83a3ffa7ddc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_dfs = []\n",
    "clean_processed_files = []\n",
    "files_failures = []\n",
    "bad_dfs =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda8ac5-f35a-47e2-9ff3-25d0656031fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_clean = [file.name for file in TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN.glob(\"*.csv\")]\n",
    "files_failures = [file.name.split(\"-\", maxsplit=1)[-1] for file in TR_01_FAILURE_CASES_CSV.glob(\"*.csv\")]\n",
    "cleaned = [file.name for file in TR_01_TEST_676_CIK_CSV_CLEANED.glob(\"*.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6e43a-70f6-40ef-b51c-74a745fac269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_clean, files_failures, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93407e7-40f6-4d39-baa9-611bf6d7c9d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pandera as pa\n",
    "\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "TR_01_TEST_676_CIK_CSV_REDUCED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_REDUCED\")\n",
    "TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN\")\n",
    "TR_01_TEST_676_CIK_CSV_CLEANED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_CLEANED\")\n",
    "TR_01_FAILURE_CASES_CSV = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_FAILURE_CASES_CSV\")\n",
    "\n",
    "filings_676_txt = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_TEST_676_CIK_TXT\")\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "           'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "           'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "           'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "           'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "           'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "           'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "cusip_eq_9_schema = pa.DataFrameSchema({\n",
    "    \"cusip9\": pa.Column(str, pa.Check(lambda s: s.str.len() == 9), required=True, nullable=False) ,\n",
    "    \"value\":  pa.Column(float, pa.Check(lambda s: s != 0.0), required=True, nullable=False),\n",
    "    \"shares\": pa.Column(float, pa.Check(lambda s: s != 0.0), required=True, nullable=False)\n",
    "})\n",
    "\n",
    "cleaned = [file.name for file in TR_01_TEST_676_CIK_CSV_CLEANED.glob(\"*.csv\")]\n",
    "# bad_dfs =[]\n",
    "origin_clean = [file.name for file in TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN.glob(\"*.csv\")]\n",
    "files_failures = [file.name.split(\"-\", maxsplit=1)[-1] for file in TR_01_FAILURE_CASES_CSV.glob(\"*.csv\")]\n",
    "\n",
    "for index, cik in enumerate(selected_cik):\n",
    "    for file in TR_01_TEST_676_CIK_CSV_REDUCED.glob(f\"{cik}-*.csv\"):\n",
    "        if file.name not in set(origin_clean + files_failures + cleaned):\n",
    "            try:\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "                # os.system(f\"code \"+ file.as_posix())\n",
    "                # i = input(\"did you correct the file?\")\n",
    "                # if i == \"yes\":\n",
    "                #     print(f\"file: {file} is finished\")\n",
    "                #     continue\n",
    "\n",
    "                # else: \n",
    "                #     sys.exit()\n",
    "            df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "\n",
    "            try:\n",
    "                cusip_eq_9_schema.validate(df[columns], lazy=True)\n",
    "                df.to_csv(Path.joinpath(TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN, file.name), index=False)\n",
    "                # print(f\"Originally Clean: {file.name}\")\n",
    "            except pa.errors.SchemaErrors as e:\n",
    "                failure_cases = e.failure_cases\n",
    "                failure_cases = (failure_cases.assign(df_file=file,\n",
    "                                                     df_cik=cik,\n",
    "                                                     df_rdate=df.rdate,\n",
    "                                                     df_fdate=df.fdate,\n",
    "                                                     df_value=df.value,\n",
    "                                                     df_shares=df.shares))\n",
    "                failure_cases.to_csv(Path.joinpath(TR_01_FAILURE_CASES_CSV, f\"bad-{file.name}\"), index=False)\n",
    "                # bad_dfs.append(failure_cases)\n",
    "                cleaned_df = df[~df.index.isin(failure_cases[\"index\"])]\n",
    "                # !!! TODO !!! Now empty cleaned_df get written to `csv` files. Need to add/test code\n",
    "                # the code below!!!\n",
    "                # if not cleaned_df.empty:\n",
    "                #     cleaned_df.to_csv(Path.joinpath(TR_01_TEST_676_CIK_CSV_CLEANED, file.name), index=False)\n",
    "                # print(f\"CIK: {cik}. Year: {file.name.split('-')[2]}, File: {file.name}.\")\n",
    "                # print(f\"Total rows: {df.shape[0]}. Bad rows: {failure_cases.shape[0]}. Clean rows: {cleaned_df.shape[0]}\")\n",
    "                # print(f\"{round((failure_cases.shape[0] / df.shape[0]) * 100, 2)}% bad rows\", end='\\n#############\\n')\n",
    "                # cleaned_dfs.append(cleaned_df)\n",
    "    df, failure_cases, cleaned_df = (None, None, None)\n",
    "\n",
    "        \n",
    "\n",
    "        # dfs.append(df)\n",
    "        # df = pl.concat(dfs).to_pandas().astype(pd_dtypes_validation)\n",
    "        # df = df.to_pandas().astype(pd_dtypes_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf881d47-9930-40e2-82f4-32fdb7299817",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running `pandera` validation through the **ALL** reduced `.csv` with `fdate` <= '2014-01-01'\n",
    "* `csv` filings from **dropbox** will be used only for the range from the `absolute beginnig` to `2013-12-31`\n",
    "* `parquet` filings downloaded and parsed by my called **sec_app** will be used from `2014-01-01` and on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef324d8-12c0-4c21-bde0-a13e65a1cf33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pandera as pa\n",
    "\n",
    "TR_01_ALL_CSV_CLEANED = Path(r'/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED')\n",
    "\n",
    "TR_01_ALL_CSV_REDUCED = \\\n",
    "    Path(r'/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_REDUCED')\n",
    "TR_01_ALL_CSV_CLEANED = \\\n",
    "    Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED\")\n",
    "TR_01_FAILURE_CASES_CSV = \\\n",
    "    Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_FAILURE_CASES_CSV\")\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "           'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "           'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "           'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "           'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "           'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "           'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "# pandera schema\n",
    "validation_schema = pa.DataFrameSchema({\n",
    "    \"cusip9\": pa.Column(str,\n",
    "                       pa.Check(lambda s: s.str.len() == 9),\n",
    "                       required=True, nullable=False),\n",
    "    \"value\":  pa.Column(float, pa.Check(lambda s: s != 0.0),required=True, nullable=False),\n",
    "    \"shares\": pa.Column(float, pa.Check(lambda s: s != 0.0), required=True, nullable=False)\n",
    "        })\n",
    "\n",
    "cleaned = [file.name for file in TR_01_ALL_CSV_CLEANED.glob(\"*.csv\")]\n",
    "files_failures = [file.name.split(\"-\", maxsplit=1)[-1] for file in TR_01_FAILURE_CASES_CSV.glob(\"*.csv\")]\n",
    "cutoff_date = '2014-01-01'\n",
    "\n",
    "for file in TR_01_ALL_CSV_REDUCED.glob(f\"*.csv\"):\n",
    "    if file.name not in set(files_failures + cleaned):\n",
    "        try:\n",
    "            df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "        except Exception as e:\n",
    "            print(f\"Problem reading file... {file.name}\")\n",
    "            print(e)\n",
    "        df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "        if df.fdate.max()  >= pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue\n",
    "\n",
    "        try:\n",
    "            validation_schema.validate(df, lazy=True)\n",
    "            df.to_csv(Path.joinpath(TR_01_ALL_CSV_CLEANED, file.name), index=False)\n",
    "            # print(f\"Originally Clean: {file.name}\")\n",
    "        except pa.errors.SchemaErrors as e:\n",
    "            failure_cases = e.failure_cases\n",
    "            failure_cases = (failure_cases.assign(df_file=file,\n",
    "                                                 df_cik=df.cik,\n",
    "                                                 df_rdate=df.rdate,\n",
    "                                                 df_fdate=df.fdate)).astype({'failure_case':str})\n",
    "            failure_cases.to_csv(Path.joinpath(TR_01_FAILURE_CASES_CSV, f\"bad-{file.name}\"), index=False)\n",
    "            # bad_dfs.append(failure_cases)\n",
    "            cleaned_df = df[~df.index.isin(failure_cases[\"index\"])]\n",
    "            # !!! TODO !!! Now empty cleaned_df get written to `csv` files. Need to add/test code\n",
    "            # the code below!!!\n",
    "            if not cleaned_df.empty:\n",
    "                cleaned_df.to_csv(Path.joinpath(TR_01_ALL_CSV_CLEANED, file.name), index=False)\n",
    "\n",
    "df, failure_cases, cleaned_df = (None, None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4a8cb-98f0-44ce-9564-8666a664cc66",
   "metadata": {},
   "source": [
    "### Move cleaned `csv` for 676 cik from `TR_01_TEST_676_CIK_CSV_CLEANED_BOTH` to `TR_01_ALL_CSV_CLEANED` with all `.csv`\n",
    "* **Only** the filings before **`2014-01-01`** are moved\n",
    "* It's one-off code to move already cleaned filings for 676 cik that were active between 1999 and 2020 to the common folder with all `csv` that were passed through the `pandera` data quality tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c42c9-2d25-4d0c-b25e-f0b3b20ed4e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pandera as pa\n",
    "\n",
    "TR_01_ALL_CSV_CLEANED = \\\n",
    "    Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED\")\n",
    "\n",
    "TR_01_TEST_676_CIK_CSV_CLEANED_BOTH = \\\n",
    "    Path(r'/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH')\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "           'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "           'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "           'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "           'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "           'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "           'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "cutoff_date = '2014-01-01'\n",
    "\n",
    "for file in TR_01_TEST_676_CIK_CSV_CLEANED_BOTH.glob(f\"*.csv\"):\n",
    "    # print(file.name)\n",
    "    df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "    df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "    # print(df.head(2))\n",
    "    if df.empty: continue\n",
    "    if df.fdate.max()  >= pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue \n",
    "    df.to_csv(Path.joinpath(TR_01_ALL_CSV_CLEANED, file.name), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c4a46-abf2-473a-9836-ca4f99002849",
   "metadata": {},
   "source": [
    "### Move cleaned `parquet` for 676 cik from `TR_02_TEST_676_CIK_PARQ_SEC_APP` to `TR_02_ALL_PARQ_SEC_APP` with all `parquet`\n",
    "* **Only** the filings from **`2014-01-01`** and onwards are moved\n",
    "* It's a one-off code to move already cleaned filings for 676 cik that were active between 1999 and 2020 to the common folder with all `parquet` that were passed through the `pandera` data quality tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8c9e9-661d-4885-91a6-c330137bf651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import shutil\n",
    "\n",
    "TR_02_ALL_PARQ_SEC_APP = \\\n",
    "    Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_ALL_PARQ_SEC_APP')\n",
    "\n",
    "TR_02_TEST_676_CIK_PARQ_SEC_APP = \\\n",
    "    Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_TEST_676_CIK_PARQ_SEC_APP')\n",
    "\n",
    "columns_sec_app = ['cik', 'cusip','value', 'shares','rdate', 'fdate',\\\n",
    "            'accession_number', 'submission_type', 'type', 'dsource', 'file']\n",
    "\n",
    "pd_dtypes_validation_sec_app = {'cusip': str, 'submission_type': 'category', 'value': 'float64', \n",
    "            'shares': 'float64', 'type': 'category', 'cik' : 'int64',\n",
    "            'accession_number': 'category',  'dsource': 'category', 'file':'category'}\n",
    "\n",
    "pl_dtypes_sec_app = {'cusip': str ,'submission_type': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str,\n",
    "            'cik' : pl.Int64, 'accession_number': str,  'dsource': str, 'file': str}\n",
    "\n",
    "cutoff_date = '2014-01-01'\n",
    "\n",
    "for file in TR_02_TEST_676_CIK_PARQ_SEC_APP.glob(f\"*.parquet\"):\n",
    "    # print(file.name)\n",
    "    df = pl.read_parquet(file, columns=columns_sec_app)\n",
    "    df = df.to_pandas().astype(pd_dtypes_validation_sec_app)\n",
    "    # print(df.head(2))\n",
    "    if df.empty: continue\n",
    "    if df.fdate.max() < pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue \n",
    "    else: shutil.copy(file, Path.joinpath(TR_02_ALL_PARQ_SEC_APP, file.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d6814-377c-4621-b4fa-ce8ae6f51ecb",
   "metadata": {},
   "source": [
    "### Remove entries with `cusip` containing 'TEGIES' from every file, `csv` and `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ce9e0-78b5-4ac1-a18e-f3e3b05eebec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(list(dropbox_csv.glob('*.csv')) + list(sec_app_parq.glob('*.parquet')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a5582-a545-4a08-ac05-ba92a178d723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "def remove_cusip_w_substring(dir_csv, dir_parq):\n",
    "    \"\"\"\n",
    "    input: file directories, csv and parquet\n",
    "    returns: removes cusip containing certain substring and \n",
    "    saves it back to the original files\n",
    "    csv or parquet\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in set(list(dropbox_csv.glob('*.csv')) + list(sec_app_parq.glob('*.parquet'))):\n",
    "        try:\n",
    "            if file.suffix == '.parquet' and file.exists():\n",
    "                df = pd.read_parquet(file)\n",
    "                if not df.query('cusip.str.contains(\"TEGIES\")').empty: \n",
    "                    print(f'found TEGIES in {file} ')\n",
    "                    df = df.drop(df.query('cusip.str.contains(\"TEGIES\")').index)\n",
    "                    df.to_parquet(file, index=False)\n",
    "                    print('saved new df to parquet', file)\n",
    "            elif file.suffix == '.csv' and file.exists():\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                if not df.query('cusip9.str.contains(\"TEGIES\")').empty: \n",
    "                    print(f'found TEGIES in {file} ')\n",
    "                    df = df.drop(df.query('cusip9.str.contains(\"TEGIES\")').index)\n",
    "                    df.to_csv(file, index=False)\n",
    "                    print('saved new df to csv', file)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4770da0-c55d-4072-94e7-8a47a0ee63c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dropbox_csv = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED\")\n",
    "sec_app_parq = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_ALL_PARQ_SEC_APP')\n",
    "\n",
    "# remove_cusip_w_substring(dropbox_csv, sec_app_parq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328141c-5c76-472e-ad85-aa81907acbac",
   "metadata": {},
   "source": [
    "## After the code above generated new set of `csv` we manually review and clean the obvious ones\n",
    "* It's done in the notebook `cik_cleaning_tool.ipynb`\n",
    "* It was a very long manual process where both `csv` and `parquet` filings were connected in the data cleaning viz and manually cleaned as much as possible. The typical errors are:\n",
    "     - non division by 1000. Now this big dataset is mostly made of shares divided by 1000\n",
    "     - swapped columns for `shares` and `value`. \n",
    "     - bad `value` in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd37db-3824-4282-baaa-e77f6aa20d54",
   "metadata": {},
   "source": [
    "### Here we take the cleaned `csv` files and convert them to `parquet`\n",
    "* We're adding new column `data_load` with default value `manual_csv_2023_01_01_01_01`. It means this is the data that was manually dealt with and cleaned. It's the first baseline and a one-off task. \n",
    "* The data is from the very beginning to the 'fdate' < `2014-01-01`\n",
    "* All the rest will come from the manually cleaned `parquet` filings\n",
    "* !!! **IMPORTANT** !!! this code multiplies manually cleaned `csv` value by 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219803d-a979-45f7-a0c1-aae55a121af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "def clean_csv_to_parquet(csv_folder, parq_folder):\n",
    "    \"\"\"\n",
    "    !!! IMPORTANT !!! this code multiplies manually cleaned csv value by 1000\n",
    "    input: list of csv file paths to change a bit and convert to parquet\n",
    "    returns: enriched parquet from cleaned csv\n",
    "    \"\"\"\n",
    "    columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "    pl_dtypes = {'cik' : pl.Int64, 'cusip9': str, 'value': pl.Float64, 'shares': pl.Float64, 'address': str,\n",
    "                 'form': str, 'shrsOrPrnAmt': str, 'putCall': str, 'nameOfIssuer': str, 'titleOfClass': str,\n",
    "                 'type': str, 'dsource': str}\n",
    "\n",
    "    pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "                'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "                'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "                'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "    new_names={'address': 'accession_number', \"form\": 'submission_type', 'putCall':'put_call', 'titleOfClass':'title_of_class',\n",
    "               'nameOfIssuer':'name_of_issuer', 'cusip9':'cusip', 'shrsOrPrnAmt':'shares_bonds'}\n",
    "\n",
    "    final_columns = [\n",
    "        \"cik\",\n",
    "        \"cik_name\",\n",
    "        \"rdate\",\n",
    "        \"fdate\",        \n",
    "        \"cusip\",\n",
    "        \"name_of_issuer\",       \n",
    "        \"value\",\n",
    "        \"shares\",\n",
    "        \"title_of_class\",\n",
    "        \"shares_bonds\",\n",
    "        \"put_call\",\n",
    "        \"accession_number\",\n",
    "        \"submission_type\",\n",
    "        \"type\",\n",
    "        \"file\",\n",
    "        'dsource',\n",
    "        \"entry_total\",\n",
    "        \"value_total\",\n",
    "        \"data_load\"\n",
    "    ]\n",
    "    \n",
    "    final_dtypes = {\n",
    "            \n",
    "            \"cik\": \"Int64\",\n",
    "            'cik_name': str,\n",
    "            \"rdate\": \"datetime64[ns]\",           \n",
    "            \"fdate\": \"datetime64[ns]\",\n",
    "            \"cusip\": str,\n",
    "            \"name_of_issuer\": str,\n",
    "            \"value\": \"float64\",\n",
    "            \"shares\": \"float64\",\n",
    "            \"title_of_class\": str,    \n",
    "            \"shares_bonds\": str,\n",
    "            \"put_call\": str,\n",
    "            \"accession_number\": str,\n",
    "            \"submission_type\": str,\n",
    "            \"type\": str,\n",
    "            \"file\": str,\n",
    "            'dsource': str,\n",
    "            \"entry_total\": \"Int64\",\n",
    "            \"value_total\": \"float64\",\n",
    "            \"data_load\": \"datetime64[ns]\"\n",
    "        }\n",
    "    path_list = list(csv_folder.glob('*.csv'))\n",
    "    cutoff_date = '2014-01-01'\n",
    "    \n",
    "    for file_path in path_list:\n",
    "        try:\n",
    "            df = pl.read_csv(file_path, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "            df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "            if df.empty or df.fdate.max() >= pd.to_datetime(cutoff_date,format='%Y-%m-%d'): continue\n",
    "            df = (df.assign(value=df.value*1_000,\n",
    "                            cik_name=None,\n",
    "                            entry_total=None,\n",
    "                            value_total=None,\n",
    "                            file=file_path.as_posix(),\n",
    "                            address=df.address.str.split('/').str[1].str.split('.').str[0],\n",
    "                            data_load=pd.to_datetime('2023-01-01 00:00:00'))\n",
    "                    .rename(columns=new_names)\n",
    "                    .reindex(columns=final_columns)\n",
    "                    .astype(final_dtypes))\n",
    "            \n",
    "            df.to_parquet(Path.joinpath(parq_folder, file_path.stem + f\"-{df.head(1).fdate[0].strftime('%Y-%m-%d')}.parquet\"), index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739c250-fbd7-4241-a181-62a0005bcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "clean_csv_0_2013 = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_ALL_CSV_CLEANED\")\n",
    "clean_parq_0_2013 = Path(r'/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_02_CLEANED_PARQ_0_2013')\n",
    "\n",
    "test_parq = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/test_parq')\n",
    "\n",
    "# data = clean_csv_to_parquet(clean_csv_0_2013,test_parq)\n",
    "clean_csv_to_parquet(clean_csv_0_2013,clean_parq_0_2013)\n",
    "# Wall time: 34min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16397c42-b990-41ae-9d9c-d86d99249262",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)\n",
    "# data.info()\n",
    "# data.value.sum()/1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b4d3a-6b89-416b-a19d-a93a4c8487e6",
   "metadata": {},
   "source": [
    "## Here we take the cleaned `parquet` files and:\n",
    "* Adding new column `data_load` with default value `'2023-01-01 00:00:00'`. It means this is the data that was manually dealt with and cleaned. It's the first baseline and a one-off task. \n",
    "* Filter data to only have filings where 'fdate' >= `2014-01-01`\n",
    "* All the rest will come from the manually cleaned `csv` filings\n",
    "* !!! **IMPORTANT** !!! this code multiplies manually cleaned `parquet` value by 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b7f6c-e48c-4756-ac5e-be38d199e761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "def parq_from_2014(parq_clean_folder, parq_final_folder):\n",
    "    \"\"\"\n",
    "    !!! IMPORTANT !!! this code multiplies manually cleaned csv value by 1000\n",
    "    input: list of parquet file paths to multiply by 1_000 and add `data_load` column\n",
    "    returns: enriched parquet\n",
    "    \"\"\"\n",
    "#     columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "#             'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "#     pl_dtypes = {'cik' : pl.Int64, 'cusip9': str, 'value': pl.Float64, 'shares': pl.Float64, 'address': str,\n",
    "#                  'form': str, 'shrsOrPrnAmt': str, 'putCall': str, 'nameOfIssuer': str, 'titleOfClass': str,\n",
    "#                  'type': str, 'dsource': str}\n",
    "\n",
    "#     pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "#                 'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "#                 'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "#                 'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "#     new_names={'address': 'accession_number', \"form\": 'submission_type', 'putCall':'put_call', 'titleOfClass':'title_of_class',\n",
    "#                'nameOfIssuer':'name_of_issuer', 'cusip9':'cusip', 'shrsOrPrnAmt':'shares_bonds'}\n",
    "\n",
    "    final_columns = [\n",
    "        \"cik\",\n",
    "        \"cik_name\",\n",
    "        \"rdate\",\n",
    "        \"fdate\",        \n",
    "        \"cusip\",\n",
    "        \"name_of_issuer\",       \n",
    "        \"value\",\n",
    "        \"shares\",\n",
    "        \"title_of_class\",\n",
    "        \"shares_bonds\",\n",
    "        \"put_call\",\n",
    "        \"accession_number\",\n",
    "        \"submission_type\",\n",
    "        \"type\",\n",
    "        \"file\",\n",
    "        'dsource',\n",
    "        \"entry_total\",\n",
    "        \"value_total\",\n",
    "        \"data_load\"\n",
    "    ]\n",
    "    \n",
    "    final_dtypes = {\n",
    "            \n",
    "            \"cik\": \"Int64\",\n",
    "            'cik_name': str,\n",
    "            \"rdate\": \"datetime64[ns]\",           \n",
    "            \"fdate\": \"datetime64[ns]\",\n",
    "            \"cusip\": str,\n",
    "            \"name_of_issuer\": str,\n",
    "            \"value\": \"float64\",\n",
    "            \"shares\": \"float64\",\n",
    "            \"title_of_class\": str,    \n",
    "            \"shares_bonds\": str,\n",
    "            \"put_call\": str,\n",
    "            \"accession_number\": str,\n",
    "            \"submission_type\": str,\n",
    "            \"type\": str,\n",
    "            \"file\": str,\n",
    "            'dsource': str,\n",
    "            \"entry_total\": \"Int64\",\n",
    "            \"value_total\": \"float64\"\n",
    "        }\n",
    "    path_list = list(parq_clean_folder.glob('*.parquet'))\n",
    "    cutoff_date = '2014-01-01'\n",
    "    prior_2014 = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/prior_2014')\n",
    "    \n",
    "    for file_path in path_list:\n",
    "        try:          \n",
    "            df = pl.read_parquet(file_path) \n",
    "            df = df.to_pandas().astype(final_dtypes)\n",
    "            if df.empty or df.fdate.max() < pd.to_datetime(cutoff_date,format='%Y-%m-%d'):\n",
    "                df.to_parquet(Path.joinpath(prior_2014, 'prior_2014-'+file_path.name), index=False)\n",
    "                continue               \n",
    "            df = (df.assign(data_load=pd.to_datetime('2023-01-01 00:00:00'),\n",
    "                            value=df.value*1_000)\n",
    "                  .reindex(columns=final_columns))\n",
    "\n",
    "            \n",
    "            df.to_parquet(Path.joinpath(parq_final_folder, file_path.name), index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53019b6-c977-44e8-a4a7-14f8df274028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "TR_02_ALL_PARQ_SEC_APP = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_ALL_PARQ_SEC_APP')\n",
    "TR_02_FINAL_PARQ_2014_2023_02_17 = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/TR_02_FINAL_PARQ_2014_2023_02_17')\n",
    "\n",
    "# test_parq = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/test_parq')\n",
    "\n",
    "parq_from_2014(TR_02_ALL_PARQ_SEC_APP, TR_02_FINAL_PARQ_2014_2023_02_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0c1d7-340c-4459-a76a-2472a3f194fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'prior_2014-'+file_path.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d593c-865b-4588-9a00-9762feb5342d",
   "metadata": {},
   "source": [
    "## Rename `data_load` to `created_at` and add `updated_at`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad977d-7968-43c0-bb55-5b88a505964d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "def add_updated_at(folder):    \n",
    "    final_dtypes = {\n",
    "            \n",
    "            \"cik\": \"Int64\",\n",
    "            'cik_name': str,\n",
    "            \"rdate\": \"datetime64[ns]\",           \n",
    "            \"fdate\": \"datetime64[ns]\",\n",
    "            \"cusip\": str,\n",
    "            \"name_of_issuer\": str,\n",
    "            \"value\": \"float64\",\n",
    "            \"shares\": \"float64\",\n",
    "            \"title_of_class\": str,    \n",
    "            \"shares_bonds\": str,\n",
    "            \"put_call\": str,\n",
    "            \"accession_number\": str,\n",
    "            \"submission_type\": str,\n",
    "            \"type\": str,\n",
    "            \"file\": str,\n",
    "            'dsource': str,\n",
    "            \"entry_total\": \"Int64\",\n",
    "            \"value_total\": \"float64\"\n",
    "        }\n",
    "    \n",
    "    final_columns = [\n",
    "        \"cik\",\n",
    "        \"cik_name\",\n",
    "        \"rdate\",\n",
    "        \"fdate\",        \n",
    "        \"cusip\",\n",
    "        \"name_of_issuer\",       \n",
    "        \"value\",\n",
    "        \"shares\",\n",
    "        \"title_of_class\",\n",
    "        \"shares_bonds\",\n",
    "        \"put_call\",\n",
    "        \"accession_number\",\n",
    "        \"submission_type\",\n",
    "        \"type\",\n",
    "        \"file\",\n",
    "        'dsource',\n",
    "        \"entry_total\",\n",
    "        \"value_total\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\"\n",
    "    ]\n",
    "    path_list = list(folder.glob('*.parquet'))\n",
    "\n",
    "    for file_path in path_list:\n",
    "        try:          \n",
    "            df = pl.read_parquet(file_path) \n",
    "            df = df.to_pandas().astype(final_dtypes)           \n",
    "            df = (df.assign(updated_at=pd.to_datetime('2023-01-01 00:00:00'))\n",
    "                    .rename(columns={'data_load':'created_at'})\n",
    "                    .reindex(columns=final_columns))\n",
    "\n",
    "            \n",
    "            df.to_parquet(file_path, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9866403-ea1f-4938-ad2a-9715a6f21c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "final_folder = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_PARQ_ALL')\n",
    "test = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/test_parq')\n",
    "\n",
    "add_updated_at(final_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a7109-c28a-4134-8419-2404444f4c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b82535-faa9-474a-85b9-b5ba5c5b52fd",
   "metadata": {},
   "source": [
    "## Add `data_load_run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646d4b4-1c2a-434f-b2e8-76e806dc8e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "def add_data_load_run(folder):    \n",
    "    final_dtypes = {\n",
    "            \n",
    "            \"cik\": \"Int64\",\n",
    "            'cik_name': str,\n",
    "            \"rdate\": \"datetime64[ns]\",           \n",
    "            \"fdate\": \"datetime64[ns]\",\n",
    "            \"cusip\": str,\n",
    "            \"name_of_issuer\": str,\n",
    "            \"value\": \"float64\",\n",
    "            \"shares\": \"float64\",\n",
    "            \"title_of_class\": str,    \n",
    "            \"shares_bonds\": str,\n",
    "            \"put_call\": str,\n",
    "            \"accession_number\": str,\n",
    "            \"submission_type\": str,\n",
    "            \"type\": str,\n",
    "            \"file\": str,\n",
    "            'dsource': str,\n",
    "            \"entry_total\": \"Int64\",\n",
    "            \"value_total\": \"float64\",\n",
    "            \"created_at\": \"datetime64[ns]\",\n",
    "            \"updated_at\": \"datetime64[ns]\"\n",
    "        }\n",
    "    \n",
    "    final_columns = [\n",
    "        \"cik\",\n",
    "        \"cik_name\",\n",
    "        \"rdate\",\n",
    "        \"fdate\",        \n",
    "        \"cusip\",\n",
    "        \"name_of_issuer\",       \n",
    "        \"value\",\n",
    "        \"shares\",\n",
    "        \"title_of_class\",\n",
    "        \"shares_bonds\",\n",
    "        \"put_call\",\n",
    "        \"accession_number\",\n",
    "        \"submission_type\",\n",
    "        \"type\",\n",
    "        \"file\",\n",
    "        'dsource',\n",
    "        \"entry_total\",\n",
    "        \"value_total\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "        \"data_load_run\"\n",
    "    ]\n",
    "    path_list = list(folder.glob('*.parquet'))\n",
    "\n",
    "    for file_path in path_list:\n",
    "        try:          \n",
    "            df = pl.read_parquet(file_path) \n",
    "            df = df.to_pandas().astype(final_dtypes)           \n",
    "            df = (df.assign(data_load_run = \"2023-01-01-01-01\")\n",
    "                    .reindex(columns=final_columns))\n",
    "            \n",
    "            df.to_parquet(file_path, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c627c86-e0a6-4a2c-936b-da24a85e3380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "final_folder = Path(r'/Users/yo_macbook/Documents/app_data/TR_02_PARQ_ALL')\n",
    "# test = Path(r'/Users/yo_macbook/Documents/app_data/sec_apps_data/test_parq')\n",
    "\n",
    "add_data_load_run(final_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bf502-33bf-414b-8675-dc573d34b67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6384f84-c1e8-4d6f-9285-0cbbe1bf0d22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "# from pandas_profiling import ProfileReport\n",
    "from scipy import stats\n",
    "\n",
    "selected_cik = [2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN\")\n",
    "TR_01_TEST_676_CIK_CSV_CLEANED = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_CLEANED\")\n",
    "both = Path(r\"/Users/yo_macbook/Documents/app_data/dropbox_13f_files/processed_tables/TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\")\n",
    "\n",
    "# both = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\") # fanpc\n",
    "\n",
    "columns = ['cik', 'cusip9','value', 'shares','rdate', 'fdate',\\\n",
    "            'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "pl_dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str, 'putCall': str,\n",
    "            'shrsOrPrnAmt': str, 'value': pl.Float64, 'shares': pl.Float64, 'type': str, 'nameOfIssuer': str,\n",
    "            'cik' : pl.Int64, 'address': str,  'dsource': str}\n",
    "\n",
    "pd_dtypes_validation = {'cusip9': str , 'titleOfClass': str, 'form': 'category',\n",
    "            'putCall': 'category', 'shrsOrPrnAmt': 'category', 'value': 'float64',\n",
    "            'shares': 'float64', 'type': 'category', 'nameOfIssuer': str,\n",
    "            'cik' : 'int64', 'address': 'category',  'dsource': 'category'}\n",
    "\n",
    "\n",
    "cleaned = [file for file in TR_01_TEST_676_CIK_CSV_CLEANED.glob(\"*.csv\")]\n",
    "origin_clean = [file for file in TR_01_TEST_676_CIK_CSV_ORIGIN_CLEAN.glob(\"*.csv\")]\n",
    "both_clean = [file for file in both.glob(\"*.csv\")]\n",
    "\n",
    "\n",
    "\n",
    "cik_dfs = []\n",
    "for index, cik in enumerate(selected_cik[:10]):\n",
    "    file_dfs = []\n",
    "    for file in set(both_clean):\n",
    "    # for file in set(cleaned + origin_clean):\n",
    "        if file.name.split(\"-\")[0] == str(cik):\n",
    "            try:\n",
    "                df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "                \n",
    "                df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "                if df.empty: continue\n",
    "\n",
    "                df = (df.assign(row_value_zscore = stats.zscore(df.value),\n",
    "                                file_value_sum = df.value.sum(),\n",
    "                                file_value_max = df.value.max(),\n",
    "                                file_value_min = df.value.min(),\n",
    "                                file_record_count = df.shape[0],\n",
    "                                quarter=df.rdate.dt.to_period(freq=\"Q\").astype(str)))\n",
    "                df_short = df[['cik', 'cusip9', 'rdate', 'fdate',\n",
    "                               'address', 'file_value_sum', 'file_value_max',\n",
    "                               'file_value_min', 'file_record_count', 'quarter']].head(1)\n",
    "               \n",
    "\n",
    "                file_dfs.append(df_short)\n",
    "                df = None\n",
    "            except Exception as e:\n",
    "                print(f\"Problem reading file... {file.name}\")\n",
    "                print(e)\n",
    "                # os.system(f\"code \"+ file.as_posix())\n",
    "                # i = input(\"did you correct the file?\")\n",
    "                # if i == \"yes\":\n",
    "                #     print(f\"file: {file} is finished\")\n",
    "                #     continue\n",
    "\n",
    "                # else: \n",
    "                #     sys.exit()\n",
    "        \n",
    "    cik_df = pd.concat(file_dfs)\n",
    "    file_dfs = None\n",
    "\n",
    "    cik_dfs.append(cik_df)\n",
    "big_df = pd.concat(cik_dfs)\n",
    "    # df = pl.concat(dfs).to_pandas().astype(pd_dtypes_validation)\n",
    "    # df = df.to_pandas().astype(pd_dtypes_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788634fc-9c28-4e73-a8ec-a511cbb6944b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair import datum\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "input_dropdown = alt.binding_select(options=selected_cik, name='cik ')\n",
    "cik_selection = alt.selection_single(fields=['cik'], bind=input_dropdown)\n",
    "brush = alt.selection(type='multi')\n",
    "\n",
    "scatter = alt.Chart(big_df).mark_point().transform_calculate(value_billion=\"datum.value / 1000000000\")\\\n",
    "    .encode(\n",
    "    alt.X('quarter:O'),\n",
    "    alt.Y('file_value_sum:Q'),\n",
    "    \n",
    "    # alt.Row('cik'),\n",
    "    tooltip=['quarter:O','address:N', \n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$.3s\") ,\n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$~s\"),\n",
    "             alt.Tooltip('fdate:T')\n",
    "            ]\n",
    "    # alt.Tooltip(['quarter:O','accession_number:N', 'value:O']),\n",
    "    \n",
    ").add_selection(cik_selection\n",
    ").transform_filter(cik_selection\n",
    ").add_selection(brush\n",
    ").properties(width=800, height=200)\n",
    "\n",
    "ranked_text = alt.Chart(big_df).mark_text().encode(\n",
    "    y=alt.Y('row_number:O',axis=None)\n",
    ").transform_window(\n",
    "    row_number='row_number()'\n",
    ").transform_filter(\n",
    "    brush\n",
    ").transform_window(\n",
    "    rank='rank(row_number)'\n",
    ").transform_filter(\n",
    "    alt.datum.rank<5\n",
    ")\n",
    "\n",
    "# Data Tables\n",
    "address = ranked_text.encode(text='address:N').properties(title='address')\n",
    "quarter = ranked_text.encode(text='quarter:O').properties(title='quarter')\n",
    "value = ranked_text.encode(text='file_value_sum:Q').properties(title='value')\n",
    "text = alt.hconcat(address, quarter, value) # Combine data tables\n",
    "\n",
    "alt.vconcat(\n",
    "    scatter,\n",
    "    text\n",
    ").resolve_legend(\n",
    "    color=\"independent\"\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947f9d5-8f23-4d51-a088-83bd3c97ac5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "\n",
    "pn.extension(\"vega\", sizing_mode=\"stretch_width\")\n",
    "\n",
    "\n",
    "theme = pn.state.session_args.get(\"theme\", [b\"default\"])[0].decode()\n",
    "if theme == \"dark\":\n",
    "    alt.themes.enable(\"dark\")\n",
    "else:\n",
    "    alt.themes.enable(\"default\")\n",
    "\n",
    "    \n",
    "    \n",
    "import altair as alt\n",
    "from altair import datum\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "input_dropdown = alt.binding_select(options=selected_cik, name='cik ')\n",
    "cik_selection = alt.selection_single(fields=['cik'], bind=input_dropdown, name='cik')\n",
    "brush = alt.selection(type='interval', name='brush')\n",
    "\n",
    "scatter = alt.Chart(big_df).mark_point().transform_calculate(value_billion=\"datum.value / 1000000000\")\\\n",
    "    .encode(\n",
    "    alt.X('quarter:O'),\n",
    "    alt.Y('file_value_sum:Q'),\n",
    "    \n",
    "    # alt.Row('cik'),\n",
    "    tooltip=['quarter:O','address:N', \n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$.3s\") ,\n",
    "             alt.Tooltip('file_value_sum:Q', format=\"$~s\"),\n",
    "             alt.Tooltip('fdate:T')\n",
    "            ]\n",
    "    # alt.Tooltip(['quarter:O','accession_number:N', 'value:O']),\n",
    "    \n",
    ").add_selection(cik_selection\n",
    ").transform_filter(cik_selection\n",
    ").add_selection(brush\n",
    ").properties(width=800, height=200)\n",
    "\n",
    "vega_pane = pn.pane.Vega(scatter, debounce=10, height=600)\n",
    "\n",
    "@pn.depends(vega_pane.selection.param.brush, vega_pane.selection.param.cik)\n",
    "def filtered_table(selection, selection2):\n",
    "    return selection\n",
    "    if not selection:\n",
    "        return \"## No selection\"\n",
    "    # query = \" & \".join(\n",
    "    #     f'{crange[0]:.3f} <= `{col}` <= {crange[1]:.3f}'\n",
    "    #     for col, crange in selection.items()\n",
    "    # )\n",
    "    # return pn.pane.DataFrame(data.query(query))\n",
    "\n",
    "\n",
    "# Data Tables\n",
    "\n",
    "\n",
    "table = pn.Row(filtered_table, height=300, scroll=True)\n",
    "component = pn.Column(vega_pane, table).servable()\n",
    "component\n",
    "\n",
    "# template = pn.template.FastListTemplate(\n",
    "#     site=\"Awesome Panel\",\n",
    "#     title=\"Panel supports Vega and Altair Selections\",\n",
    "#     accent=\"#F08080\",\n",
    "#     main=[component],\n",
    "# ).servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa475f82-d1ac-4482-a6bf-f639672193d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "both = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_01_TEST_676_CIK_CSV_CLEANED_BOTH\")\n",
    "l = ['105495-0001193125-04-000834.csv', '105495-0001193125-03-057541.csv','105495-0001193125-03-018135.csv',\n",
    "    '105495-0000927016-03-001711.csv', '105495-0000927016-03-000073.csv', '105495-0000927016-02-004805.csv',\n",
    "     '105495-0000927016-02-003580.csv', '105495-0000927016-02-002002.csv', '105495-0000927016-02-000170.csv',\n",
    "     '105495-0000927016-01-503075.csv', '105495-0000927016-01-501869.csv']\n",
    "\n",
    "for file in set(both_clean):\n",
    "    if file.name in l:\n",
    "        try:\n",
    "            print(Path.joinpath(both, file.name))\n",
    "            df = pl.read_csv(file, columns=columns, dtypes=pl_dtypes, parse_dates=True) \n",
    "            df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "            df = (df.assign(value=df.value/1000))\n",
    "            df.to_csv(Path.joinpath(both, file.name), index=False)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "\n",
    "# big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cecad-c328-4801-bdcd-f064b8d7d1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.address.iloc[0]\n",
    "# df.value.sum()\n",
    "file.name\n",
    "Path.joinpath(both_clean, file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8b984-1e33-4416-aaf0-e4237e200373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# more_than_one_match = {'file': [], 'bad_cusip': [], 'new_cusip': []}\n",
    "# cik_big_dfs[:3]\n",
    "df.head(),\n",
    "df.shape\n",
    "\n",
    "# pandas formatting, format\n",
    "format_dict = {col_name: '${:,.0f}' for col_name in cik_df.select_dtypes(float).columns}\n",
    "# override the percentage column\n",
    "format_dict['row_value_zscore'] = '{:.2f}'\n",
    "format_dict['shares'] = '{:.0f}'\n",
    "\n",
    "# cik_df.head().style.format(format_dict)\n",
    "# cik_df.sort_values(by=['value'], ascending=False).head(3).style.format(format_dict)\n",
    "\n",
    "# summary statistics\n",
    "# from skimpy import skim\n",
    "# skim(cik_df)\n",
    "\n",
    "#####################\n",
    "# import sweetviz as sv\n",
    "\n",
    "# my_report = sv.analyze(cik_df[['file_value_sum','quarter']],target_feat='file_value_sum')\n",
    "# # # my_report.show_html() # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n",
    "# my_report.show_notebook(layout='vertical') # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n",
    "\n",
    "###########################\n",
    "# import data_describe as dd\n",
    "# dd.data_summary(cik_df[['value','file_value_sum','quarter']]) # , as_percentage=True\n",
    "# dd.data_heatmap(cik_df[['value','file_value_sum','quarter']])\n",
    "# from IPython.display import display\n",
    "# display is used to show plots from inside a loop\n",
    "# for col in ['file_value_sum','quarter']:\n",
    "#     display(dd.distribution(cik_df[['file_value_sum','quarter']], plot_all=False).plot_distribution(col))\n",
    "#####\n",
    "# dist = dd.distribution(df)\n",
    "# dist\n",
    "# dist.plot_distribution(\"value\", mode='hist')\n",
    "# dist.skew_value\n",
    "    \n",
    "# dd.correlation_matrix(cik_df)\n",
    "# dd.correlation_matrix(cik_df, cluster=True)\n",
    "#####\n",
    "# dd.scatter_plots(cik_df[['file_value_sum','quarter']], mode='diagnostic', threshold={'Outlying': 0.5})\n",
    "# dd.scatter_plots(cik_df[['file_value_sum','quarter']], mode='all')\n",
    "#####\n",
    "# c = dd.cluster(df)\n",
    "# c.show()\n",
    "##############\n",
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(cik_df[['file_value_sum']], title=\"Pandas Profiling Report\")\n",
    "profile.to_widgets()\n",
    "\n",
    "# cik_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d89ad-baf0-4c70-83aa-1ac3e5ae2649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cik_df.query(\"file_value_sum ==9467399625.0\")\n",
    "big_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf244c-aa2d-458a-9abf-53930958685a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "brush = alt.selection(type='interval')\n",
    "points = alt.Chart(big_df[['cik', 'address', 'file_value_sum', 'quarter']]).mark_point().encode(\n",
    "    x='quarter:O',\n",
    "    y='file_value_sum:Q',\n",
    "    \n",
    "    color=alt.condition(brush, 'quarter', alt.value('lightgray'))\n",
    ").add_selection(brush)\n",
    "\n",
    "bars = alt.Chart(big_df[['cik', 'address', 'file_value_sum', 'quarter']]).mark_bar().encode(\n",
    "    y='address:N',\n",
    "    # color='fdate:T',\n",
    "    x='file_value_sum'\n",
    ").transform_filter(brush)\n",
    "# points\n",
    "points & bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27a470-2f6a-4359-92bf-01ac082ee6f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "value_10B_schema = pa.DataFrameSchema({\n",
    "    \"value\": pa.Column(float, pa.Check(lambda s: s <= 10000000), required=True, nullable=False)\n",
    "})\n",
    "\n",
    "try:\n",
    "    value_10B_schema.validate(cik_df) , #lazy=True\n",
    "\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    failure_cases = e.failure_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0d0da-b540-4ec7-81d1-0f4a28c68e15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "\n",
    "for index, row in big_bad_df.iterrows():\n",
    "    # if (row.failure_case not in processed_cusip) and (row.failure_case not in processed_no_match):\n",
    "    file_name = Path(row.df_file).name.split(\".\")[0].split(\"-\", maxsplit=1)[-1]\n",
    "    print(row.df_file)\n",
    "    bad_cik = row.df_cik\n",
    "    bad_cusip = row.failure_case\n",
    "    bad_rdate = row.df_rdate.date()\n",
    "\n",
    "    match = cusip_676.query(f'address.str.contains(\"{bad_cik}/{file_name}\") &\\\n",
    "                  cusip.notna() &\\\n",
    "                  cusip.str.contains(@bad_cusip)')['cusip'].drop_duplicates().squeeze() # &\\\n",
    "    \n",
    " # & rdate == @bad_rdate'\n",
    "\n",
    "    if not any(match):\n",
    "        print(\"no match\")\n",
    "        processed_no_match.append(row.failure_case)\n",
    "        continue\n",
    "    elif any(match) and not isinstance(match, pd.core.series.Series):       \n",
    "        print(f\"bad cusip: {bad_cusip} --- new cusip: {match}\")\n",
    "        df = pl.read_csv(row.df_file, columns=columns, dtypes=pl_dtypes, parse_dates=True)\n",
    "        df = df.to_pandas().astype(pd_dtypes_validation)\n",
    "        df = (df.assign(cusip9=df.cusip9.str.replace(bad_cusip, match)))\n",
    "        df.to_csv(row.df_file, index=False)\n",
    "        processed_cusip.append(row.failure_case)\n",
    "        \n",
    "    elif isinstance(match, pd.core.series.Series):\n",
    "        print(\"more than one match\")\n",
    "        more_than_one_match['file'].append(row.df_file)\n",
    "        more_than_one_match['bad_cusip'].append(bad_cusip)\n",
    "        more_than_one_match['new_cusip'].append(match.to_list())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab1125-7104-4018-a594-13037882a99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isinstance(match, pd.core.series.Series)\n",
    "# isinstance([], list)\n",
    "# pd.dtype(match)\n",
    "match.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82aee57-aac7-4a44-8579-95c53761df1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.query(\"cusip9== '690733209'\")\n",
    "len(processed_cusip)\n",
    "# processed_cusip[:3]\n",
    "# match.head(1).squeeze()\n",
    "# bad_cusip # '565849'\n",
    "\n",
    "len(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65299a58-b81e-4afb-87b2-87b247f49fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\")\n",
    "# cusip_676 = pd.read_parquet(Path.joinpath(directory, \"value_total_676.parquet\")) \n",
    "# cusip_676.head()\n",
    "# cusip_676 = big_df_cusip_676.drop_duplicates(subset=['cusip'])\n",
    "\n",
    "##\n",
    "# md_dir = Path(r\"E:\\app_data\\sec_apps_data\\speed_test\\filings_13f_full\\master_data\\cusip\")\n",
    "# cusip_merged_final = pd.read_parquet(Path.joinpath(md_dir, \"cusip_merged_final.parquet\")) \n",
    "# cusip_merged_final.head()\n",
    "##\n",
    "bad_cik = 3520\n",
    "bad_cusip = \"0733209\"\n",
    "cusip_676.query(f'address.str.contains(\"{bad_cik}/\") &\\\n",
    "                  cusip.notna() &\\\n",
    "                  cusip.str.contains(\"{bad_cusip}\") &\\\n",
    "                  rdate == \"1999-12-31\"')['cusip']\n",
    "# \"0733209\" in (cusip_676.cusip.values or cusip_merged_final.cusip.values)\n",
    "# \"088033G10\" in (cusip_676.cusip.values or cusip_merged_final.cusip.values)\n",
    "# for cusip in cusip_676.cusip:\n",
    "#     if \"G03910109\" == cusip:\n",
    "#         print(cusip)\n",
    "# for cusip in cusip_merged_final.cusip:\n",
    "#     if \"G03910109\" == cusip:\n",
    "#         print(cusip)\n",
    "# cusip_676.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222cfa0-851f-4f89-9d43-663fda4fc6a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# md_02_ftd_cusip_ticker.parquet\n",
    "# cusip_merged_final.query(\"cusip.str.contains('45920010')\")\n",
    "cusip_676.query('cusip.notna() & cusip.str.contains(\"141705SH\")')\n",
    "# cusip_676.query('cusip.notna() & cusip.str.contains(\"45920010\")')\n",
    "\n",
    "# df.query('index.isin([24, 80])').head(7)\n",
    "\n",
    "# 0     26       1957109\n",
    "# 1    183     718154107\n",
    "# 2   1369     297659104\n",
    "# 3   4145     362320103\n",
    "# 4   4358      16962105\n",
    "# 5   4373      67543101\n",
    "# 6   4383      90078109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fa4b9-7593-4b67-ae32-8557361283a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cusip_676.query('cusip.notna() & cusip.str.contains(\"E\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ffa5f-5b51-42a0-bd2e-f1ea34e014a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_types_schema = pa.DataFrameSchema({\n",
    "    \"cik\": pa.Column('int64'),\n",
    "    \"cusip8\": pa.Column(str),\n",
    "    \"cusip9\": pa.Column(str, pa.Check(lambda s: s.str.len() == 9)),\n",
    "    \"rdate\": pa.Column(\"datetime64\"),\n",
    "    \"fdate\": pa.Column(\"datetime64\"),\n",
    "    \"value\": pa.Column(\"float64\"),\n",
    "    \"shares\": pa.Column(\"float64\")\n",
    "    \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db972ac-f0d2-45c0-a680-2048812d63ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_types_schema.validate(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f19d91-80ee-41f3-ba00-dd35be76221a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_types_schema = pa.DataFrameSchema({\n",
    "    \"cusip9\": pa.Column(str, pa.Check(lambda s: ~s.str.contains(\"\\+|\\-\")))\n",
    "                        })\n",
    "    # \"cik\": pa.Column('int64'),\n",
    "    # \"cusip8\": pa.Column(str),\n",
    "    # \"rdate\": pa.Column(\"datetime64\"),\n",
    "    # \"fdate\": pa.Column(\"datetime64\"),\n",
    "    # \"value\": pa.Column(\"float64\"),\n",
    "    # \"shares\": pa.Column(\"float64\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b63469-5729-4100-ae28-ab9da1293a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Pandera also allows validating value ranges for numerical columns\n",
    "# value_range_schema = pa.DataFrameSchema({\n",
    "#     \"LotArea\": pa.Column(int, pa.Check(lambda s: s <= 1000000), nullable=False),\n",
    "#     \"YearBuilt\": pa.Column(int, pa.Check.in_range(1800, 2022)),\n",
    "# })\n",
    "\n",
    "value_range_schema = pa.DataFrameSchema({\n",
    "    \"cik\": pa.Column('int64'),\n",
    "    \"cusip8\": pa.Column(str, pa.Check(lambda s: s.str.len() >= 8), pa.Check(lambda s: s.str.len() <= 9)),\n",
    "    \"cusip9\": pa.Column(str, pa.Check(lambda s: s.str.len() >= 9), pa.Check(lambda s: s.str.len() <= 9)),\n",
    "\n",
    "    # \"cusip9\": pa.Column(str, pa.Check(lambda s: ~s.str.contains(\"\\+|\\-\"))),\n",
    "    # \"rdate\": pa.Column(\"datetime64\"),\n",
    "    # \"fdate\": pa.Column(\"datetime64\"),\n",
    "    # \"value\": pa.Column(\"int64\", pa.Check(lambda s: s <= 1000000), nullable=False)\n",
    "                        })\n",
    "%time value_range_schema.validate(df[columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc1015-458f-47b2-bf49-6eb9bc37a264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter = df.cusip9.str.contains('\\+')\n",
    "df.loc[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a2bbe-9ca8-41c8-87ae-87c47528b643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.cusip9.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eeb88-d8a1-446f-8374-a639f2bb8bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = filings_676_txt.rglob(\"*1006435/*.txt\")\n",
    "total_n_filings = len(list(filings_676_txt.rglob(\"*1006435/*.txt\")))\n",
    "total_n_filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cec1e5-1fcd-445c-b0a0-73a0ddd28b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(filings_676_txt.rglob(\"*.txt\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a746e-b0da-411e-8a30-2094376dc502",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the regular expression to extrtact `cusip` values\n",
    "exp_cusip = r\"\\b[A-Za-z0-9]{9}(?<![A-Za-z]{9})\\b\"\n",
    "\n",
    "# Compile the regular expression\n",
    "pattern_cusip = re.compile(exp_cusip)\n",
    "\n",
    "# Open the text file\n",
    "filings_676_txt = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_00_TEST_676_CIK_TXT\")\n",
    "files = filings_676_txt.rglob(\"*.txt\")  # -03-000131\n",
    "total_n_filings = len(list(filings_676_txt.rglob(\"*.txt\")))\n",
    "big_df = pd.DataFrame()\n",
    "###\n",
    "df_processed = pd.read_parquet(\"df_processed.parquet\")\n",
    "filings_processed = [tuple(x) for x in df_processed.itertuples(index=False, name=None)]\n",
    "###\n",
    "df_to_correct.to_parquet(\"df_to_correct.parquet\", index=False)\n",
    "filings_to_correct = [tuple(x) for x in df_to_correct.itertuples(index=False, name=None)]\n",
    "filings_other = []\n",
    "\n",
    "for file in files:\n",
    "    if file.name not in (filings_processed or filings_manually_corrected):\n",
    "        for file in files:\n",
    "            text = file.read_text()\n",
    "            # print(file)    \n",
    "            xml_pattern = r'<?xml'\n",
    "            match_xml = re.search(xml_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "            if match_xml: continue\n",
    "\n",
    "            data_dict = dict()\n",
    "            data_dict['rdate'] = datetime.strptime(\n",
    "                re.compile(r\"(?<=CONFORMED PERIOD OF REPORT:).*\")\n",
    "                .search(text)\n",
    "                .group(0)\n",
    "                .strip(),\n",
    "                \"%Y%m%d\",\n",
    "            ).date()\n",
    "\n",
    "            data_dict['fdate'] = datetime.strptime(\n",
    "                re.compile(r\"(?<=FILED AS OF DATE:).*\")\n",
    "                .search(text)\n",
    "                .group(0)\n",
    "                .strip(),\n",
    "                \"%Y%m%d\",\n",
    "            ).date()\n",
    "\n",
    "            accession = (\n",
    "                re.compile(r\"(?<=ACCESSION NUMBER:).*\")\n",
    "                .search(text)\n",
    "                .group(0)\n",
    "                .strip()+\".txt\"\n",
    "            )\n",
    "            cik = (\n",
    "                re.compile(r\"(?<=CENTRAL INDEX KEY:).*\")\n",
    "                .search(text)\n",
    "                .group(0)\n",
    "                .strip().lstrip('0')\n",
    "                )\n",
    "            data_dict['address']  = '/'.join([cik, accession])\n",
    "\n",
    "            ## !!! todo !!! problem with cases where there is no lines for entry or value total at all. code break at the missing .group(0)\n",
    "\n",
    "            entry_total = re.compile(r\"(Entry Total|Total Entry(:)?).*\", flags = re.M|re.I).search(text)\n",
    "            if entry_total:\n",
    "                entry_total = entry_total.group(0).strip()\n",
    "                entry_total = re.sub(r'\\D', '', entry_total)\n",
    "                if entry_total:\n",
    "                    entry_total = int(entry_total)\n",
    "                else:\n",
    "                    entry_total = np.nan\n",
    "            else:\n",
    "                entry_total = np.nan\n",
    "            data_dict['entry_total'] = entry_total\n",
    "\n",
    "            #######----\n",
    "\n",
    "            value_total = re.compile(\"(Value Total|Total Value(:)?).*\", flags = re.M|re.I).search(text)\n",
    "            if value_total:\n",
    "                value_total = value_total.group(0).strip()\n",
    "                value_total = re.sub(r'\\D', '', value_total)\n",
    "                if value_total:\n",
    "                    value_total = int(value_total)\n",
    "                else:\n",
    "                    value_total = np.nan\n",
    "\n",
    "            else:\n",
    "                value_total = np.nan\n",
    "            data_dict['value_total'] = value_total\n",
    "\n",
    "\n",
    "            header_df = pd.DataFrame.from_dict([data_dict]).astype({'entry_total': 'Int64', 'value_total': 'Int64'})       \n",
    "            if header_df.value_total.isna().any() or header_df.entry_total.isna().any() : \n",
    "                # print(header_df.head())\n",
    "                filings_to_correct.append((file.name, data_dict['entry_total'], data_dict['value_total']))\n",
    "            else: \n",
    "                filings_processed.append((file.name, data_dict['entry_total'], data_dict['value_total']))\n",
    "             \n",
    "            filings_other.append((file.name, data_dict['entry_total'], data_dict['value_total']))\n",
    "\n",
    "\n",
    "            matches = pattern_cusip.finditer(text)\n",
    "                # Create a list of the matched strings\n",
    "            matched_strings = [match.group(0) for match in matches]\n",
    "            matched_strings = set(matched_strings)\n",
    "            matched_strings = set([s for s in matched_strings if not re.search(r'([^\\d]{3,})', s)])\n",
    "\n",
    "            df = pd.DataFrame(matched_strings, columns=['cusip'])\n",
    "            # else:\n",
    "            #     df = pd.DataFrame(\"no_cusip\", columns=['cusip'])\n",
    "\n",
    "            df = pd.concat([header_df, df], axis=1).ffill()\n",
    "            big_df = pd.concat([big_df, df])\n",
    "\n",
    "            # Filter out the strings that contain only non-digit characters\n",
    "            # filtered_strings = set([s for s in matched_strings if any(c.isdigit() for c in s) and not all(c.isalpha() for c in s)])\n",
    "\n",
    "# df_to_correct = pd.DataFrame(filings_to_correct, columns=['file', 'entry_total', 'value_total'])\n",
    "# df_processed = pd.DataFrame(filings_processed, columns=['file', 'entry_total', 'value_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbd234-9537-40f8-aec1-9ca79bf73b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# total_n_filings # 67629\n",
    "# len(filings_processed) # 32178\n",
    "# filings_processed[-50:-1]\n",
    "# len(filings_manually_corrected)\n",
    "# len(filings_to_correct) # 8906\n",
    "# filings_to_correct[0]\n",
    "# filings_other[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0beeb69-ff54-4410-b938-897ecd873cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75009b45-c07d-4572-929f-b4591cd324eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# big_df.query(\"value_total.isna() & entry_total.notna()\").drop_duplicates(subset=[\"address\"]).shape\n",
    "# # big_df.head()\n",
    "# cusip_from_txt = (big_df.astype({'rdate':'datetime64', 'fdate':'datetime64'})\n",
    "#                 .drop_duplicates(subset=[\"cusip\"]))\n",
    "\n",
    "cusip_from_txt.head()\n",
    "# cusip_from_txt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b6ad2-7b88-4e83-8956-fbf1773da42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# big_df = big_df.drop_duplicates() # before  # (15354045, 6)\n",
    "# pd_dtypes = {'cusip': 'category' , 'value_total': 'Int64', 'entry_total': 'Int64', 'address': 'category',\n",
    "#            'rdate': 'datetime64', 'fdate': 'datetime64'}\n",
    "\n",
    "# directory = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\")\n",
    "big_df = big_df.astype(pd_dtypes)\n",
    "big_df.info()\n",
    "# big_df.to_parquet(Path.joinpath(directory, 'value_total_676.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35f41a-262c-4b4a-aee5-4a3fb35b040e",
   "metadata": {},
   "source": [
    "### Checking files that need to be corrected (no value or entry or both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee7cb0-617d-4319-9593-55734e0ec563",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### big_df2 = pd.read_parquet(Path.joinpath(directory, \"value_total_676.parquet\")) \n",
    "## check '21175/0000021175-02-000013.txt' \n",
    "dont_have_value_in_txt = ['1026710', '1011659', '1041885']\n",
    "# casaes with total entries, but no total values\n",
    "fixed_value_cik = ('1008895' , '1002152', '1006435', '1011659', '1026710', '1033427',\n",
    "                   '1033505' , '1035463', '1037389', '1040197', '1040273', '1041885', '1053013',\n",
    "                   '1056516', '1077583', '1079112' , '1082339', '1082621', '1082917', '1085041',\n",
    "                   '1085227', '1085936', '1088950', '1105468', '21175', '320335', '36066', '40545',\n",
    "                   '741073', '754811', '790354', '861177', '866361', '869367', '872732', '877134',\n",
    "                   '884566', '889232', '902584', '919079', '92230', '928047', '936944', '938076',\n",
    "                   '939219', '947822')\n",
    "cik = '947822'\n",
    "####\n",
    "(big_df2.query(f\"value_total.isna() & \\\n",
    "                entry_total.notna() & \\\n",
    "                address.str.contains('|'.join(@fixed_value_cik))==False  \") \n",
    "         .drop_duplicates(subset=['address']))\n",
    "\n",
    "# print(big_df2.query(f\"value_total.isna() & \\\n",
    "#                 entry_total.notna() & \\\n",
    "#                 address.str.contains('|'.join(@fixed_value_cik))==False  \") \n",
    "#          .drop_duplicates(subset=['address'])['address'])\n",
    "\n",
    "# l = (big_df2.query(f\"value_total.isna() & \\\n",
    "#                 entry_total.notna() & \\\n",
    "#                 address.str.contains('|'.join(@fixed_value_cik))==False & address.str.contains('{cik}')  \") \n",
    "#          .drop_duplicates(subset=['address'])['address']).to_list()\n",
    "\n",
    "\n",
    "# df.query(\"cusip == '066050105'\")\n",
    "# value_total\n",
    "# matched_strings\n",
    "# [s for s in matched_strings if not re.search(r'([^\\d]{3,})', s).group(0)]\n",
    "# [s for s in matched_strings if not re.search(r'([^\\d]{3,})', s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9708f-2453-49d5-a0c2-8a59c5bcccee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = filings_676_txt.rglob(f\"{cik}/*.txt\")  # -03-000131\n",
    "\n",
    "# l = ('1008895/0001008895-06-000002.txt',\n",
    "#  '1008895/0001008895-06-000009.txt',\n",
    "#  '1008895/0001008895-06-000011.txt')\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    if f\"{cik}/\"+file.name in l:\n",
    "        text = file.read_text()\n",
    "######################################  Value Total is on a wrong line. Below the correct one  ###########\n",
    "############ itendify the correct number/amount (current version only works if thousand separator is present) ##\n",
    "##### adds correct amount in a correct place. After \"Value Total\"   ###################\n",
    "\n",
    "        # select text 200 tokens befire and 200 after the \"Entry Total\" and work with it\n",
    "#         pattern = re.compile(r\"(?:^.{1,200})(?:Entry Total:?)(?:.{1,400}$)\", flags=re.M|re.DOTALL)\n",
    "#         working_text = (pattern.findall(text)[0])\n",
    "#         # print(working_text, sep=\"\\n\")\n",
    "      \n",
    "#         lines = working_text.splitlines()\n",
    "#         for index, line in enumerate(lines):\n",
    "#             pattern_v_total = re.compile(r\"((Value Total|Total Value)\\s*(:?))\", flags=re.I)\n",
    "#             match_v_total = pattern_v_total.search(line)\n",
    "#             if match_v_total:\n",
    "#                 pattern_v_total_amnt = re.compile(r\"((Value Total|Total Value)\\s*(:?).*\\d+)\", flags=re.I)\n",
    "#                 match_v_total_amnt = pattern_v_total_amnt.search(line)\n",
    "#                 if match_v_total_amnt:\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     pattern_next_line_amnt = re.compile(r\"(.*(\\d+))\", flags=re.I)\n",
    "#                     match_next_line_amnt = pattern_next_line_amnt.search(lines[index+1])\n",
    "#                     if match_next_line_amnt:\n",
    "#                         updated_line = match_v_total.group()+match_next_line_amnt.group() \n",
    "#                         updated_text = re.sub(pattern_v_total,updated_line, text)\n",
    "#                         # print(updated_text[3500:6000], \"#\" * 10, sep=\"\\n\")\n",
    "#                         file.write_text(updated_text)       \n",
    "\n",
    "            \n",
    "######################################  Value Total is on a wrong line. Above the correct one  ###########\n",
    "############ itendifying the correct number/amount (current version only works if thousand separator is present) ##\n",
    "##### adds correct amount in a correct place. After \"Value Total\"   ###################\n",
    "##### also uses Path.read_text() and write_text() instead of `open with`\n",
    "#         start_str = \"Entry Total\"\n",
    "#         end_str = \"Value Total\"\n",
    "#         match = re.search(r\"{}(.*){}\".format(start_str, end_str), text, flags=re.DOTALL)\n",
    "#         if match:\n",
    "#             value = match.group(1)\n",
    "#             value = re.findall(r'\\b\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?\\b', value)[-1]\n",
    "#             value = re.sub(r'\\.\\d+', '', value)  \n",
    "#             value = re.sub(r'\\D', '', value)\n",
    "\n",
    "#         value_total_old = re.compile(r\"^(Form 13F Information Table Value Total).*?$\", flags=re.M)\n",
    "#         sub_match = re.search(value_total_old, match.group())\n",
    "#         new_text = re.sub(value_total_old, fr\"Form 13F Information Table Value Total: {value} \", text)\n",
    "#         print(new_text[3500:6000], \"#\" * 10, sep=\"\\n\")\n",
    "#         file.write_text(new_text)\n",
    "\n",
    "#  \n",
    "############################# swap multiple lines in text for one  #################################\n",
    "#         entry_total = re.compile(r\"(\\nForm 13F Information Table Value Total:\\n\\n     \\$)\", re.IGNORECASE).finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         # print(matches)\n",
    "#         if matches:  \n",
    "#             updated_text = text.replace(r\"\"\"Form 13F Information Table Value Total:\n",
    "\n",
    "#      $\"\"\", \"Form 13F Information Table Value Total $\")\n",
    "\n",
    "#             print(updated_text[3500:5000])\n",
    "\n",
    "#               #### Write the file out again\n",
    "#         with open(file, 'w') as file:\n",
    "#             file.write(updated_text)     \n",
    "\n",
    "#############################################################################\n",
    "#         entry_total = re.compile(r\"(Form 13F Information Table Value Total:\\n\\$).*\").finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         matches =  [match.replace(\"Form 13F Information Table Value Total:\\n$\", \"\") for match in matches]\n",
    "#         # print(matches)\n",
    "#         if matches:  \n",
    "#             # updated_text = text.replace(\"Value (x $1000) Total\", \"(x $1000) Value Total\", 1)\n",
    "#             # updated_text = text.replace(\"Table Value $\", \"Table Value Total $\")\n",
    "#             updated_text = re.sub(r\"(Form 13F Information Table Value Total:\\n\\$).*\",\\\n",
    "#                                   f\"Form 13F Information Table Value Total: {matches[0]}\", text)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "################################# Swap 2nd \"Entry Total\" for \"Value Total\"  #########################################        \n",
    "#         # code to find the 2nd occurence of the substring in the text and \n",
    "#         # substitute only this 2nd ocurrence with something else \n",
    "\n",
    "#         entry_total = re.compile(r\"(Entry Total)\", re.IGNORECASE).finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         print(matches)\n",
    "#         if len(matches) > 1:  \n",
    "#             where = [m.start() for m in re.finditer(\"Entry Total\", text)][2-1]\n",
    "#             before = text[:where]\n",
    "#             after = text[where:]\n",
    "#             after = after.replace(\"Entry Total\", \"Value Total\", 1)\n",
    "#             updated_text = before + after\n",
    "#             # print(updated_text[2000:3500])\n",
    "            \n",
    "# # #             # ### Write the file out again\n",
    "#             file.write_text(updated_text)\n",
    "    \n",
    "# #             with open(file, 'w') as file:\n",
    "# #                 file.write(updated_text)\n",
    "\n",
    "            \n",
    "            \n",
    "##########################################################################\n",
    "#         # code to find the 2nd occurence of the substring in the text and \n",
    "#         # substitute only this 2nd ocurrence with something else \n",
    "        \n",
    "#         entry_total = re.compile(r\"(Entry Total|Value Total)\").finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         print(matches)\n",
    "# #         if len(matches) > 1:  \n",
    "#             where = [m.start() for m in re.finditer(\"Entry Total\", text)][2-1]\n",
    "#             before = text[:where]\n",
    "#             after = text[where:]\n",
    "#             after = after.replace(\"Entry Total\", \"Value Total\", 1)\n",
    "#             updated_text = before + after\n",
    "#             # print(updated_text[2500:3500])\n",
    "            \n",
    "#             ### Write the file out again\n",
    "#             with open(file, 'w') as file:\n",
    "#                 file.write(updated_text)\n",
    "        \n",
    "###################################################################### Value \\(x $1000\\) Total\n",
    "#         entry_total = re.compile(r\"(Form 13F Information Table Value Total:\\n\\$).*\").finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         matches =  [match.replace(\"Form 13F Information Table Value Total:\\n$\", \"\") for match in matches]\n",
    "#         # print(matches)\n",
    "#         if matches:  \n",
    "#             # updated_text = text.replace(\"Value (x $1000) Total\", \"(x $1000) Value Total\", 1)\n",
    "#             # updated_text = text.replace(\"Table Value $\", \"Table Value Total $\")\n",
    "#             updated_text = re.sub(r\"(Form 13F Information Table Value Total:\\n\\$).*\",\\\n",
    "#                                   f\"Form 13F Information Table Value Total: {matches[0]}\", text)\n",
    "\n",
    "#             # print(updated_text[2500:3000])\n",
    "#           # #Write the file out again\n",
    "#         with open(file, 'w') as file:\n",
    "#             file.write(updated_text)\n",
    "######################### swap of regex pattern for a text string \"TotaL Value\" for \"Value Total\" ##########################\n",
    "#         entry_total = re.compile(r\"(Total Value)\", re.IGNORECASE).finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         # print(matches)\n",
    "#         if matches:  \n",
    "#             updated_text = re.sub(matches[0], \"Value Total\", text, flags=re.IGNORECASE)\n",
    "#             # print(updated_text[1000:4000])\n",
    "\n",
    "#         #  # Write the file out again\n",
    "#         with open(file, 'w') as file:\n",
    "#             file.write(updated_text)\n",
    "            \n",
    "################################# Simple Swap: \"Values Total\" for \"Value Total\"  ########################\n",
    "#         entry_total = re.compile(r\"(Value total)\", re.IGNORECASE).finditer(text)\n",
    "#         matches =  [match.group(0) for match in entry_total]\n",
    "#         print(matches)\n",
    "#         if matches:  \n",
    "#             updated_text = re.sub(matches[0], \"Value Total\", text, flags=re.IGNORECASE)\n",
    "#             # print(updated_text[2000:4000])\n",
    "\n",
    "#          # Write the file out again\n",
    "#         file.write_text(updated_text)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42196c-573d-43de-9894-39138d83d0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f553e8f-7d87-4442-b0d0-e6951a3c73da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a14df0-76bf-4027-aceb-361830fa2ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301efd3-a111-4b29-b7e2-ab8c3224193d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e536719-b8f7-48e3-a13c-e6969b463c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the delimiter, which in this case appears to be whitespace\n",
    "delimiter = '\\s+'\n",
    "file = Path(r\"C:\\users\\yo_fanpc\\Desktop\\filing_copy.txt\")\n",
    "# Read the file and create a pandas DataFrame\n",
    "# df = pd.read_csv(file, delimiter=delimiter, engine='python', header=None,  index_col=False).astype({0:str, 1:})\n",
    "\n",
    "# # Select the first 6 columns\n",
    "# # df = df[df.columns[:6]]\n",
    "\n",
    "# # display the dataframe\n",
    "# df.head()\n",
    "# df.\n",
    "\n",
    "\n",
    "\n",
    "# widths = [33, 17, 9, 9, 9, 10]\n",
    "# widths = [28, 7, 9, 16, 12, 4]\n",
    "# widths = [33, 17, 9, 9, 9, 3]\n",
    "# widths = [33, 6, 11, 14, 14, 3]\n",
    "# widths = [32, 10, 16, 9, 9, 4]\n",
    "widths = [31, 17, 9, 9, 9, 4]\n",
    "\n",
    "columns = ['issuer', 'title', 'cusip', 'value', 'shares', 'shrsprn']\n",
    "df = pd.read_fwf(file, widths=widths, names=columns,engine='python', header=None,  index_col=False, dtype=({'cusip':str})).ffill()\n",
    "\n",
    "df.to_csv(Path.joinpath(file.parent, 'filing_copy.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160db3f-e63f-46c5-bd0c-a522cfde0749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923290f-4eb9-43a7-8ca6-46b57969d22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv(Path.joinpath(file.parent, 'filing_copy.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a6bbf-5caf-4625-a63a-a1f1906d8709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd6a1d-0d96-4c29-9dec-d73371681b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae51ac-d64b-4dd0-9726-eaebf9643346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a331-3dd2-4107-95f2-84341c7f8c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cec09-83e3-441b-9e3a-733ac166d33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514b8fc-03bd-47ba-bbdf-619477cea33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed840f59-06dd-41e6-952e-cadf1889dc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933ac20-c465-43cf-bb24-b27fffbcba9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5730a0d-33d2-4e66-bb87-ee2ed5942412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4b27e-d75a-4f1b-b9be-3f6ffd781fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2243a-c06e-4e93-b5b6-2c06aa536fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3445b-e81a-472f-9744-0c5a9f1beab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7b9eb-273d-417a-9946-cf66c3310715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ad7af-8740-48ee-9b79-5d8a27a37c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa5663-520e-4abd-8b3a-89b731522d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff258bb-ff76-4d12-b40d-36d98b3f8d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90195eed-2c1f-4100-8788-ac62762b1c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6682c-21d7-4b82-856c-9e61d4bc3b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4b191-4319-4959-9825-40242db14a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffa717-8519-4cb2-bfe4-0d5d9c4645fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d500c-12f4-43f5-998e-1499b241891a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fb560-8039-479e-a034-55e9b9968cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44372310-584a-4e3b-a7f4-a1590e58d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "AB,CD,EF, JJ\n",
    "foo,20160101,a,23\n",
    "foo,20160102,a,34\n",
    "foo,20160103,a,56\n",
    "\"\"\"\n",
    "lambda txt: len(txt) <= 10\n",
    "# data = pl.read_csv(io.StringIO(txt))\n",
    "# data = data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe79f6b-df65-4778-be7f-16a5d3b614a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# different pandas dtypes\n",
    "\n",
    "dtypes =    {\n",
    "        \"ID\": str,\n",
    "        \"accessionNumber\": str,\n",
    "        \"cikManager\": \"Int64\",\n",
    "        \"periodOfReport\": \"datetime64[ns]\",\n",
    "        \"report_Quarter\": \"Int64\",\n",
    "        \"report_Year\": \"Int64\",\n",
    "        \"submissionType\": str,\n",
    "        \"isAmendment\": bool,\n",
    "        \"amendmentType\": str,\n",
    "        \"filedAsOfDate\": \"datetime64[ns]\",\n",
    "        \"entryTotal\": \"Int64\",\n",
    "        \"valueTotal\": \"float64\",\n",
    "        \"cusip\": str,\n",
    "        \"nameOfIssuer\": str,\n",
    "        \"titleOfClass\": str,\n",
    "        \"sharesValue\": \"float64\",\n",
    "        \"sharesHeldAtEndOfQtr\": \"Int64\",\n",
    "        \"securityType\": str,\n",
    "        \"putCall\": str,\n",
    "        \"xml_flag\": str,\n",
    "        \"created_at\": \"datetime64[ns]\",\n",
    "        \"edgar_path\": str,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ae19f64c7897bc26be3645e5b4b678b67b3c5e5a93a5db3ce83cda1cd1694c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
