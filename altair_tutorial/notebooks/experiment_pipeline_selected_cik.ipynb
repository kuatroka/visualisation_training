{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5262fe0-1b8d-4ae5-9173-e61f09907c00",
   "metadata": {},
   "source": [
    "### Experimental data pipeline for selected `cik` \n",
    "* Let's start with identifying the universe of `cik` we will be working with\n",
    "* For now, we will only deal with `cik` that were active both in 1999 and 2020 years\n",
    "* The fact is there is a lot of bad data and focusing on these `cik` first, will provide the longest range of active `cik`\n",
    "* Here is the list of `cik` derived through the code from `pycon_2018_altair.ipynb` notebook\n",
    "<details><summary>(List of cik)</summary>\n",
    "[2230,3520,5272,7195,7789,9015,10742,14661,16972,18349,18748,19475,19617,21175,22657,24386,35442,35527,36066,36104,36644,36966,38777,39263,40417,40545,44365,45319,49205,50863,51762,51812,51964,52234,53417,59558,59951,60086,61227,67698,70858,71210,71259,72971,73124,80255,84616,89014,92230,93751,98758,102212,102909,105495,108572,200217,201772,216851,276101,310051,312348,313028,313807,314949,314957,314984,315014,315032,315038,315054,315066,315080,315157,315297,315498,316011,318989,320335,320376,351051,351173,351262,354204,356264,700529,704051,707179,712537,713676,714142,720672,723204,728083,728100,728618,732905,733020,740272,740913,741073,743127,750641,754811,757657,759944,762152,763212,763848,764068,764106,764112,764529,764532,765443,769317,769954,769963,775368,776867,778963,779519,788714,790354,790502,791191,791490,796848,799003,799004,801051,806097,807249,807985,808722,809339,809443,810265,810384,810386,810672,810716,811360,811454,813917,813933,814133,814375,816788,819535,820027,820123,820124,820289,820478,820743,821197,822581,823621,825293,829407,831001,831571,836372,837592,842782,842941,846222,846633,846788,846797,850401,850529,852743,854157,857508,859872,860486,860561,860580,860585,860643,860644,860645,860662,860748,860828,860857,861176,861177,861462,861787,862469,866361,866842,868491,869178,869179,869353,869367,872080,872163,872259,872573,872732,873630,874791,877134,877338,878228,881432,883511,883677,883782,883790,883803,883961,883965,884300,884314,884414,884423,884541,884546,884548,884566,884589,885062,885415,886982,887402,887777,887818,889232,891287,891478,893738,894205,894300,894309,895213,895421,897070,897378,897599,898358,898382,898399,898413,899211,900169,900529,900973,902219,902367,902464,902584,903064,903944,903947,903949,905567,905591,905608,906304,908195,909151,909661,911274,912938,914933,914976,915287,915325,916542,917579,918893,919079,919185,919192,919458,919489,919497,919530,919538,919859,920440,920441,921531,921669,922127,922439,922898,922940,923093,923116,923469,924166,924171,924181,926688,926833,926834,928047,928196,928566,928568,928633,930441,931097,932024,932974,933429,934639,934999,936698,936753,936936,936941,936944,937394,937522,937589,937615,937760,937886,938076,938206,938487,938582,938592,938759,939219,940445,941560,943719,944234,944804,945625,945631,947822,947996,948518,948669,949012,949509,949615,949623,949853,1000097,1000742,1002152,1002672,1002784,1004244,1005354,1005607,1005817,1006364,1006378,1006407,1006435,1007280,1007399,1007524,1008322,1008877,1008894,1008895,1008929,1008937,1009003,1009005,1009012,1009016,1009022,1009076,1009207,1009209,1009232,1009254,1009258,1009262,1010873,1010911,1011443,1011659,1013234,1013536,1013538,1013701,1014306,1014315,1014736,1014738,1015079,1015083,1015086,1015308,1016150,1016287,1016683,1016972,1017115,1017645,1017918,1018331,1018674,1018825,1019231,1020066,1020317,1020580,1020585,1020617,1020918,1021008,1021117,1021223,1021249,1021258,1021642,1021926,1023279,1024716,1025421,1026200,1026710,1027451,1027796,1027817,1029160,1030618,1030815,1031972,1032814,1033225,1033427,1033475,1033505,1033974,1033984,1034184,1034196,1034524,1034541,1034546,1034549,1034642,1034771,1034886,1035350,1035463,1035912,1036248,1036325,1037389,1037558,1037763,1037792,1038661,1039565,1039807,1040190,1040197,1040198,1040210,1040273,1040592,1040762,1041241,1041885,1042046,1044207,1044797,1044905,1044924,1044929,1044936,1046187,1047339,1048921,1049648,1049650,1050442,1050463,1050470,1051359,1052100,1053013,1053054,1053055,1054074,1054425,1054522,1054554,1054677,1055290,1055544,1055963,1055964,1055966,1056053,1056288,1056466,1056488,1056491,1056515,1056516,1056527,1056549,1056559,1056581,1056593,1056807,1056821,1056825,1056827,1056831,1056859,1056958,1056973,1057395,1057439,1058022,1058470,1058800,1059187,1061186,1061768,1062938,1065349,1065350,1066816,1067324,1067926,1067983,1068829,1070134,1071483,1072843,1074027,1074034,1074266,1074273,1076598,1077148,1077583,1078013,1078246,1078658,1078841,1079112,1079114,1079736,1079738,1079930,1080071,1080107,1080117,1080132,1080166,1080171,1080173,1080197,1080201,1080351,1080374,1080380,1080381,1080382,1080386,1080493,1080523,1080628,1080818,1081019,1081198,1082020,1082215,1082327,1082339,1082461,1082491,1082509,1082621,1082917,1083323,1083340,1084207,1084208,1084683,1085041,1085163,1085227,1085601,1085936,1086477,1086483,1086611,1086619,1086762,1086763,1088859,1088875,1088950,1089707,1089755,1089911,1089991,1090413,1091561,1091860,1091923,1092203,1092290,1092351,1092903,1093276,1093589,1094584,1094749,1095836,1096783,1097218,1097278,1097833,1100710,1101250,1102062,1102578,1102598,1103245,1103738,1103804,1103882,1103887,1104186,1104329,1104366,1105468,1105471,1105497,1105837,1105863,1105909,1106129,1106191,1106500,1106505,1106832,1107261,1107310,1108893,1108965,1108969,1109147,1110806,1113629,1114618,1114739,1114928,1115941,1116247,1125727,1125816,1129770,1133219,1134152,1140334,1140771,1142031,1142062,1158583,1389426,1398739,1469219]\n",
    "</details>\n",
    "* Currently, I go one cik at a time to manually check and correct bad `.csv` files from `E:\\app_data\\dropbox_13f_files\\processed_tables\\processed_tables_copy` folder\n",
    "* Folder `experiment_select_cik_csv` conains the manually cleaned `cik` and two dirty: **36104** and  **36966**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c15987-9f6d-4862-9fad-8519bcfef672",
   "metadata": {},
   "source": [
    "#### Cleaned so far:\n",
    "2230?\n",
    "3520?\n",
    "5272 # sort of done.\n",
    "7195 # sort of done.\n",
    "7789 # was good.\n",
    "9015 # fixed.\n",
    "10742 # was good\n",
    "14661 # was good\n",
    "16972 # was good\n",
    "18748 was good\n",
    "19475 was good\n",
    "19617 was good\n",
    "22657 sorted\n",
    "24386 was good\n",
    "35442 sorted\n",
    "35527 sorted\n",
    "36066 sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29097e54-1f65-4451-a6cf-994164f3c28f",
   "metadata": {},
   "source": [
    "### We will work with two folders:\n",
    "1. Input with `csv`\n",
    "2. Output with `parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896b8200-efee-4cde-b283-2c034a3df266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T21:01:02.376351Z",
     "iopub.status.busy": "2023-01-06T21:01:02.376351Z",
     "iopub.status.idle": "2023-01-06T21:01:02.399663Z",
     "shell.execute_reply": "2023-01-06T21:01:02.399431Z",
     "shell.execute_reply.started": "2023-01-06T21:01:02.376351Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "FROM_EXPERIMENT_CSV_IN = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_02_EXP_SELECT_CIK_CSV\")\n",
    "TO_EXPERIMENT_PARQUET = Path(r\"E:\\app_data\\dropbox_13f_files\\processed_tables\\TR_03_EXP_SELECT_CIK_PARQUET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471432c4-1544-450c-9691-dd5cf9d36bf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T22:49:45.620537Z",
     "iopub.status.busy": "2023-01-06T22:49:45.620537Z",
     "iopub.status.idle": "2023-01-06T22:49:45.643536Z",
     "shell.execute_reply": "2023-01-06T22:49:45.643536Z",
     "shell.execute_reply.started": "2023-01-06T22:49:45.620537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# option 1: loading files with os.walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import os\n",
    "import pandera as pa\n",
    "import io\n",
    "import textwrap\n",
    "\n",
    "columns = ['cik', 'cusip8', 'cusip9','rdate', 'fdate','value', 'shares',\\\n",
    "           'address', 'form', 'shrsOrPrnAmt', 'putCall', 'nameOfIssuer', 'titleOfClass', 'type', 'dsource']\n",
    "\n",
    "dtypes = {'cusip8': str, 'cusip9': str , 'titleOfClass': str, 'form': str,\n",
    "          'putCall': str, 'shrsOrPrnAmt': str, 'value': float, 'shares': float, \n",
    "          'nameOfIssuer': str, 'cik' : int, 'address': str, 'type': str,'num5': str,\n",
    "          'deviation':str, 'shrout':str,'num3': str,'num2': str, 'num6':str,'num7': str,'num4': str,\n",
    "           'votingAuthority': str, 'in_universe': str,'prc': str, 'split': str,\n",
    "           'investmentDiscretion': str, 'rdate': str, 'fdate': str, 'dsource': str}\n",
    "    \n",
    "# if df['fdate'].max() >= pd.to_datetime('2014-01-01',format='%Y-%m-%d') : continue\n",
    "\n",
    "def concat_dfs_pd(dir_path) -> pd.DataFrame:\n",
    "    converters={'cusip8':str.upper, 'cusip9':str.upper}\n",
    "    big_df = pd.DataFrame()\n",
    "    for file in dir_path.rglob(\"*.csv\"):\n",
    "        df = pd.read_csv(file,\n",
    "                         usecols=lambda c: c in set(columns),\n",
    "                         parse_dates=['rdate','fdate'],\n",
    "                         dtype=dtypes,\n",
    "                         converters=converters,\n",
    "                         )\n",
    "        df = df.assign(ryear=df.rdate.dt.year,\n",
    "               quarter=df.rdate.dt.to_period(freq=\"Q\"))\n",
    "        \n",
    "        for col in columns:\n",
    "            if col not in df.columns:\n",
    "                df = df.assign(**{col: None})\n",
    "        \n",
    "        df = df.astype(dtypes)\n",
    "        big_df = pd.concat([big_df, df])\n",
    "    return big_df\n",
    "\n",
    "\n",
    "def concat_dfs_pl_to_df(dir_path) -> pd.DataFrame:\n",
    "    # use polars to read multiple csv, concat pl df into one big df and\n",
    "    # convert it to pandas df. All for speed. It's \n",
    "    dfs = []\n",
    "    for file in dir_path.rglob(\"*.csv\"):\n",
    "        schema = pl.scan_csv(file).schema\n",
    "        # select columns from a list of defined columns dinamically in polars\n",
    "        read_cols = list(set(schema.keys()).intersection(columns))\n",
    "        df = pl.read_csv(file, columns=read_cols, dtypes=dtypes)\n",
    "        # if our `df` misses a column from the `columns` list, we dynamically create it with None values\n",
    "        # and get the correct dtype from the dtypes list declared outside of function\n",
    "        for col in columns:\n",
    "            \n",
    "            if col not in df.columns:\n",
    "                df = df.with_column(pl.lit(None, dtype=dtypes[col]).alias(col))\n",
    "        df = df.select(columns)\n",
    "        df = df.with_columns([pl.col(\"rdate\").str.strptime(pl.Date, fmt=\"%Y%m%d\"),\n",
    "                            pl.col(\"fdate\").str.strptime(pl.Date, fmt=\"%Y%m%d\"),\n",
    "                            pl.col(\"cusip8\").str.to_uppercase(),\n",
    "                            pl.col(\"cusip9\").str.to_uppercase(),\n",
    "                            pl.lit('dropbox').alias('dsource'),\n",
    "                            ])\n",
    "\n",
    "        dfs.append(df)\n",
    "    big_df = pl.concat(dfs)\n",
    "    return big_df.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433c07d9-0bbd-4978-817e-9468fa96f772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T22:51:43.657611Z",
     "iopub.status.busy": "2023-01-06T22:51:43.657611Z",
     "iopub.status.idle": "2023-01-06T22:51:49.511522Z",
     "shell.execute_reply": "2023-01-06T22:51:49.511522Z",
     "shell.execute_reply.started": "2023-01-06T22:51:43.657611Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.2 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# df_pd = concat_dfs_pd(FROM_EXPERIMENT_CSV_IN) # Wall time: 5min 29s\n",
    "\n",
    "df_pl_pd = concat_dfs_pl_to_df(FROM_EXPERIMENT_CSV_IN) # Wall time: 5.8 sec !! 66 times faster !!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d320871-7159-4b6b-9850-66400a26d39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_duckdb_pathlib\n",
    "df_pd_pathlib.cik.value_counts(dropna=False)\n",
    "# df_pd_pathlib.query(\"cik==19991231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f455621f-1316-4b1e-91ba-cd528cdce016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T22:52:31.559276Z",
     "iopub.status.busy": "2023-01-06T22:52:31.559276Z",
     "iopub.status.idle": "2023-01-06T22:52:31.584237Z",
     "shell.execute_reply": "2023-01-06T22:52:31.584237Z",
     "shell.execute_reply.started": "2023-01-06T22:52:31.559276Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>cusip8</th>\n",
       "      <th>cusip9</th>\n",
       "      <th>rdate</th>\n",
       "      <th>fdate</th>\n",
       "      <th>value</th>\n",
       "      <th>shares</th>\n",
       "      <th>address</th>\n",
       "      <th>form</th>\n",
       "      <th>shrsOrPrnAmt</th>\n",
       "      <th>putCall</th>\n",
       "      <th>nameOfIssuer</th>\n",
       "      <th>titleOfClass</th>\n",
       "      <th>type</th>\n",
       "      <th>dsource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10742</td>\n",
       "      <td>00195710</td>\n",
       "      <td>001957109</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>10189.0</td>\n",
       "      <td>200524.0</td>\n",
       "      <td>10742/0000010742-00-000001.txt</td>\n",
       "      <td>13F-HR</td>\n",
       "      <td>SH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fwf</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10742</td>\n",
       "      <td>00195720</td>\n",
       "      <td>001957208</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>59179.0</td>\n",
       "      <td>1041655.0</td>\n",
       "      <td>10742/0000010742-00-000001.txt</td>\n",
       "      <td>13F-HR</td>\n",
       "      <td>SH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fwf</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10742</td>\n",
       "      <td>00195730</td>\n",
       "      <td>001957307</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>38624.0</td>\n",
       "      <td>10742/0000010742-00-000001.txt</td>\n",
       "      <td>13F-HR</td>\n",
       "      <td>SH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fwf</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10742</td>\n",
       "      <td>00282410</td>\n",
       "      <td>002824100</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>71430.0</td>\n",
       "      <td>1967089.0</td>\n",
       "      <td>10742/0000010742-00-000001.txt</td>\n",
       "      <td>13F-HR</td>\n",
       "      <td>SH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fwf</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10742</td>\n",
       "      <td>00811710</td>\n",
       "      <td>008117103</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>7177.0</td>\n",
       "      <td>128592.0</td>\n",
       "      <td>10742/0000010742-00-000001.txt</td>\n",
       "      <td>13F-HR</td>\n",
       "      <td>SH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fwf</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cik    cusip8     cusip9      rdate      fdate    value     shares  \\\n",
       "0  10742  00195710  001957109 1999-12-31 2000-01-24  10189.0   200524.0   \n",
       "1  10742  00195720  001957208 1999-12-31 2000-01-24  59179.0  1041655.0   \n",
       "2  10742  00195730  001957307 1999-12-31 2000-01-24   2655.0    38624.0   \n",
       "3  10742  00282410  002824100 1999-12-31 2000-01-24  71430.0  1967089.0   \n",
       "4  10742  00811710  008117103 1999-12-31 2000-01-24   7177.0   128592.0   \n",
       "\n",
       "                          address    form shrsOrPrnAmt putCall nameOfIssuer  \\\n",
       "0  10742/0000010742-00-000001.txt  13F-HR           SH    None         None   \n",
       "1  10742/0000010742-00-000001.txt  13F-HR           SH    None         None   \n",
       "2  10742/0000010742-00-000001.txt  13F-HR           SH    None         None   \n",
       "3  10742/0000010742-00-000001.txt  13F-HR           SH    None         None   \n",
       "4  10742/0000010742-00-000001.txt  13F-HR           SH    None         None   \n",
       "\n",
       "  titleOfClass type  dsource  \n",
       "0         None  fwf  dropbox  \n",
       "1         None  fwf  dropbox  \n",
       "2         None  fwf  dropbox  \n",
       "3         None  fwf  dropbox  \n",
       "4         None  fwf  dropbox  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pl_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be98b6-4e61-4b88-af65-d0f1f6126be7",
   "metadata": {},
   "source": [
    "### Notes for pandera data validation scenarios\n",
    "* `rdate` and `fdate` have to be of format .....datetime. It cannot be empty/nan/NaT\n",
    "* `cik` cannot be boolean or empty/nan\n",
    "* `address` cannot be boolean or empty/nan. It has to contain \"/\" and \".txt\". It has to be longer than 25 characters.\n",
    "* `cusip8` cannot be boolean or empty/nan\n",
    "* `cusip9` cannot be boolean or empty/nan\n",
    "* `value` cannot be boolean or empty/nan\n",
    "* `shares` cannot be boolean or empty/nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515dbc28-2490-473f-881d-f3094c927214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T21:13:28.275371Z",
     "iopub.status.busy": "2023-01-06T21:13:28.275371Z",
     "iopub.status.idle": "2023-01-06T21:13:31.990744Z",
     "shell.execute_reply": "2023-01-06T21:13:31.990744Z",
     "shell.execute_reply.started": "2023-01-06T21:13:28.275371Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3704917 entries, 0 to 705\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count    Dtype         \n",
      "---  ------        --------------    -----         \n",
      " 0   cusip8        3704917 non-null  object        \n",
      " 1   cusip9        3704917 non-null  object        \n",
      " 2   shrsOrPrnAmt  3315075 non-null  object        \n",
      " 3   putCall       28038 non-null    object        \n",
      " 4   value         3704433 non-null  float64       \n",
      " 5   shares        3704055 non-null  float64       \n",
      " 6   address       3704917 non-null  object        \n",
      " 7   rdate         3704917 non-null  datetime64[ns]\n",
      " 8   fdate         3704917 non-null  datetime64[ns]\n",
      " 9   cik           3704917 non-null  uint32        \n",
      " 10  form          3704917 non-null  object        \n",
      " 11  type          3704917 non-null  object        \n",
      " 12  ryear         3704917 non-null  int64         \n",
      " 13  quarter       3704917 non-null  period[Q-DEC] \n",
      " 14  nameOfIssuer  3704917 non-null  object        \n",
      " 15  titleOfClass  3704917 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(9), period[Q-DEC](1), uint32(1)\n",
      "memory usage: 466.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# statistics of unique values and NANs in all columns of a df\n",
    "unique_counts = (pd.DataFrame\n",
    "                   .from_records([(col, df_pd_pathlib[col].nunique(), df_pd_pathlib[col].isna().sum()) for col in df_pd_pathlib.columns],\n",
    "                          columns=['column', 'nunique', 'nans'])\n",
    "                   .sort_values(by=['nunique']))\n",
    "# print(unique_counts)\n",
    "df_pd_pathlib.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a0b7880-3601-4cfd-91b2-27a79e6acfa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-05T22:03:26.388475Z",
     "iopub.status.busy": "2023-01-05T22:03:26.387476Z",
     "iopub.status.idle": "2023-01-05T22:03:26.411475Z",
     "shell.execute_reply": "2023-01-05T22:03:26.411475Z",
     "shell.execute_reply.started": "2023-01-05T22:03:26.388475Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>CD</th>\n",
       "      <th>EF</th>\n",
       "      <th>JJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOO</td>\n",
       "      <td>20160101</td>\n",
       "      <td>A</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOO</td>\n",
       "      <td>20160102</td>\n",
       "      <td>A</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOO</td>\n",
       "      <td>20160103</td>\n",
       "      <td>A</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AB        CD EF   JJ\n",
       "0  FOO  20160101  A   23\n",
       "1  FOO  20160102  A   34\n",
       "2  FOO  20160103  A   56"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# txt = \"\"\"\n",
    "# AB,CD,EF, JJ\n",
    "# foo,20160101,a,23\n",
    "# foo,20160102,a,34\n",
    "# foo,20160103,a,56\n",
    "# \"\"\"\n",
    "\n",
    "# data = pd.read_csv(io.StringIO(txt))\n",
    "# data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
